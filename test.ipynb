{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/data2022/SN001.edf',\n",
       " './data/data2022/SN001_sleepscoring.edf',\n",
       " './data/data2022/SN002.edf',\n",
       " './data/data2022/SN002_sleepscoring.edf',\n",
       " './data/data2022/SN003.edf',\n",
       " './data/data2022/SN003_sleepscoring.edf',\n",
       " './data/data2022/SN004.edf',\n",
       " './data/data2022/SN004_sleepscoring.edf',\n",
       " './data/data2022/SN005.edf',\n",
       " './data/data2022/SN005_sleepscoring.edf',\n",
       " './data/data2022/SN006.edf',\n",
       " './data/data2022/SN006_sleepscoring.edf',\n",
       " './data/data2022/SN007.edf',\n",
       " './data/data2022/SN007_sleepscoring.edf',\n",
       " './data/data2022/SN008.edf',\n",
       " './data/data2022/SN008_sleepscoring.edf',\n",
       " './data/data2022/SN009.edf',\n",
       " './data/data2022/SN009_sleepscoring.edf',\n",
       " './data/data2022/SN010.edf',\n",
       " './data/data2022/SN010_sleepscoring.edf',\n",
       " './data/data2022/SN011.edf',\n",
       " './data/data2022/SN011_sleepscoring.edf',\n",
       " './data/data2022/SN012.edf',\n",
       " './data/data2022/SN012_sleepscoring.edf',\n",
       " './data/data2022/SN013.edf',\n",
       " './data/data2022/SN013_sleepscoring.edf',\n",
       " './data/data2022/SN015.edf',\n",
       " './data/data2022/SN015_sleepscoring.edf',\n",
       " './data/data2022/SN016.edf',\n",
       " './data/data2022/SN016_sleepscoring.edf',\n",
       " './data/data2022/SN017.edf',\n",
       " './data/data2022/SN017_sleepscoring.edf',\n",
       " './data/data2022/SN018.edf',\n",
       " './data/data2022/SN018_sleepscoring.edf',\n",
       " './data/data2022/SN019.edf',\n",
       " './data/data2022/SN019_sleepscoring.edf',\n",
       " './data/data2022/SN020.edf',\n",
       " './data/data2022/SN020_sleepscoring.edf',\n",
       " './data/data2022/SN021.edf',\n",
       " './data/data2022/SN021_sleepscoring.edf',\n",
       " './data/data2022/SN022.edf',\n",
       " './data/data2022/SN022_sleepscoring.edf',\n",
       " './data/data2022/SN023.edf',\n",
       " './data/data2022/SN023_sleepscoring.edf',\n",
       " './data/data2022/SN024.edf',\n",
       " './data/data2022/SN024_sleepscoring.edf',\n",
       " './data/data2022/SN025.edf',\n",
       " './data/data2022/SN025_sleepscoring.edf',\n",
       " './data/data2022/SN026.edf',\n",
       " './data/data2022/SN026_sleepscoring.edf',\n",
       " './data/data2022/SN027.edf',\n",
       " './data/data2022/SN027_sleepscoring.edf',\n",
       " './data/data2022/SN028.edf',\n",
       " './data/data2022/SN028_sleepscoring.edf',\n",
       " './data/data2022/SN029.edf',\n",
       " './data/data2022/SN029_sleepscoring.edf',\n",
       " './data/data2022/SN030.edf',\n",
       " './data/data2022/SN030_sleepscoring.edf',\n",
       " './data/data2022/SN031.edf',\n",
       " './data/data2022/SN031_sleepscoring.edf',\n",
       " './data/data2022/SN032.edf',\n",
       " './data/data2022/SN032_sleepscoring.edf',\n",
       " './data/data2022/SN033.edf',\n",
       " './data/data2022/SN033_sleepscoring.edf',\n",
       " './data/data2022/SN034.edf',\n",
       " './data/data2022/SN034_sleepscoring.edf',\n",
       " './data/data2022/SN035.edf',\n",
       " './data/data2022/SN035_sleepscoring.edf',\n",
       " './data/data2022/SN036.edf',\n",
       " './data/data2022/SN036_sleepscoring.edf',\n",
       " './data/data2022/SN037.edf',\n",
       " './data/data2022/SN037_sleepscoring.edf',\n",
       " './data/data2022/SN038.edf',\n",
       " './data/data2022/SN038_sleepscoring.edf',\n",
       " './data/data2022/SN039.edf',\n",
       " './data/data2022/SN039_sleepscoring.edf',\n",
       " './data/data2022/SN040.edf',\n",
       " './data/data2022/SN040_sleepscoring.edf',\n",
       " './data/data2022/SN041.edf',\n",
       " './data/data2022/SN041_sleepscoring.edf',\n",
       " './data/data2022/SN042.edf',\n",
       " './data/data2022/SN042_sleepscoring.edf',\n",
       " './data/data2022/SN043.edf',\n",
       " './data/data2022/SN043_sleepscoring.edf',\n",
       " './data/data2022/SN044.edf',\n",
       " './data/data2022/SN044_sleepscoring.edf',\n",
       " './data/data2022/SN045.edf',\n",
       " './data/data2022/SN045_sleepscoring.edf',\n",
       " './data/data2022/SN046.edf',\n",
       " './data/data2022/SN046_sleepscoring.edf',\n",
       " './data/data2022/SN047.edf',\n",
       " './data/data2022/SN047_sleepscoring.edf',\n",
       " './data/data2022/SN048.edf',\n",
       " './data/data2022/SN048_sleepscoring.edf',\n",
       " './data/data2022/SN049.edf',\n",
       " './data/data2022/SN049_sleepscoring.edf',\n",
       " './data/data2022/SN050.edf',\n",
       " './data/data2022/SN050_sleepscoring.edf',\n",
       " './data/data2022/SN051.edf',\n",
       " './data/data2022/SN051_sleepscoring.edf',\n",
       " './data/data2022/SN052.edf',\n",
       " './data/data2022/SN052_sleepscoring.edf',\n",
       " './data/data2022/SN053.edf',\n",
       " './data/data2022/SN053_sleepscoring.edf',\n",
       " './data/data2022/SN054.edf',\n",
       " './data/data2022/SN054_sleepscoring.edf',\n",
       " './data/data2022/SN055.edf',\n",
       " './data/data2022/SN055_sleepscoring.edf',\n",
       " './data/data2022/SN056.edf',\n",
       " './data/data2022/SN056_sleepscoring.edf',\n",
       " './data/data2022/SN057.edf',\n",
       " './data/data2022/SN057_sleepscoring.edf',\n",
       " './data/data2022/SN058.edf',\n",
       " './data/data2022/SN058_sleepscoring.edf',\n",
       " './data/data2022/SN059.edf',\n",
       " './data/data2022/SN059_sleepscoring.edf',\n",
       " './data/data2022/SN060.edf',\n",
       " './data/data2022/SN060_sleepscoring.edf',\n",
       " './data/data2022/SN061.edf',\n",
       " './data/data2022/SN061_sleepscoring.edf',\n",
       " './data/data2022/SN062.edf',\n",
       " './data/data2022/SN062_sleepscoring.edf',\n",
       " './data/data2022/SN063.edf',\n",
       " './data/data2022/SN063_sleepscoring.edf',\n",
       " './data/data2022/SN065.edf',\n",
       " './data/data2022/SN065_sleepscoring.edf',\n",
       " './data/data2022/SN066.edf',\n",
       " './data/data2022/SN066_sleepscoring.edf',\n",
       " './data/data2022/SN067.edf',\n",
       " './data/data2022/SN067_sleepscoring.edf',\n",
       " './data/data2022/SN068.edf',\n",
       " './data/data2022/SN068_sleepscoring.edf',\n",
       " './data/data2022/SN069.edf',\n",
       " './data/data2022/SN069_sleepscoring.edf',\n",
       " './data/data2022/SN070.edf',\n",
       " './data/data2022/SN070_sleepscoring.edf',\n",
       " './data/data2022/SN071.edf',\n",
       " './data/data2022/SN071_sleepscoring.edf',\n",
       " './data/data2022/SN072.edf',\n",
       " './data/data2022/SN072_sleepscoring.edf',\n",
       " './data/data2022/SN073.edf',\n",
       " './data/data2022/SN073_sleepscoring.edf',\n",
       " './data/data2022/SN074.edf',\n",
       " './data/data2022/SN074_sleepscoring.edf',\n",
       " './data/data2022/SN075.edf',\n",
       " './data/data2022/SN075_sleepscoring.edf',\n",
       " './data/data2022/SN076.edf',\n",
       " './data/data2022/SN076_sleepscoring.edf',\n",
       " './data/data2022/SN077.edf',\n",
       " './data/data2022/SN077_sleepscoring.edf',\n",
       " './data/data2022/SN078.edf',\n",
       " './data/data2022/SN078_sleepscoring.edf',\n",
       " './data/data2022/SN079.edf',\n",
       " './data/data2022/SN079_sleepscoring.edf',\n",
       " './data/data2022/SN080.edf',\n",
       " './data/data2022/SN080_sleepscoring.edf',\n",
       " './data/data2022/SN081.edf',\n",
       " './data/data2022/SN081_sleepscoring.edf',\n",
       " './data/data2022/SN082.edf',\n",
       " './data/data2022/SN082_sleepscoring.edf',\n",
       " './data/data2022/SN083.edf',\n",
       " './data/data2022/SN083_sleepscoring.edf',\n",
       " './data/data2022/SN084.edf',\n",
       " './data/data2022/SN084_sleepscoring.edf',\n",
       " './data/data2022/SN085.edf',\n",
       " './data/data2022/SN085_sleepscoring.edf',\n",
       " './data/data2022/SN086.edf',\n",
       " './data/data2022/SN086_sleepscoring.edf',\n",
       " './data/data2022/SN087.edf',\n",
       " './data/data2022/SN087_sleepscoring.edf',\n",
       " './data/data2022/SN088.edf',\n",
       " './data/data2022/SN088_sleepscoring.edf',\n",
       " './data/data2022/SN089.edf',\n",
       " './data/data2022/SN089_sleepscoring.edf',\n",
       " './data/data2022/SN090.edf',\n",
       " './data/data2022/SN090_sleepscoring.edf',\n",
       " './data/data2022/SN091.edf',\n",
       " './data/data2022/SN091_sleepscoring.edf',\n",
       " './data/data2022/SN092.edf',\n",
       " './data/data2022/SN092_sleepscoring.edf',\n",
       " './data/data2022/SN093.edf',\n",
       " './data/data2022/SN093_sleepscoring.edf',\n",
       " './data/data2022/SN094.edf',\n",
       " './data/data2022/SN094_sleepscoring.edf',\n",
       " './data/data2022/SN095.edf',\n",
       " './data/data2022/SN095_sleepscoring.edf',\n",
       " './data/data2022/SN096.edf',\n",
       " './data/data2022/SN096_sleepscoring.edf',\n",
       " './data/data2022/SN097.edf',\n",
       " './data/data2022/SN097_sleepscoring.edf',\n",
       " './data/data2022/SN098.edf',\n",
       " './data/data2022/SN098_sleepscoring.edf',\n",
       " './data/data2022/SN099.edf',\n",
       " './data/data2022/SN099_sleepscoring.edf',\n",
       " './data/data2022/SN100.edf',\n",
       " './data/data2022/SN100_sleepscoring.edf',\n",
       " './data/data2022/SN101.edf',\n",
       " './data/data2022/SN101_sleepscoring.edf',\n",
       " './data/data2022/SN102.edf',\n",
       " './data/data2022/SN102_sleepscoring.edf',\n",
       " './data/data2022/SN103.edf',\n",
       " './data/data2022/SN103_sleepscoring.edf',\n",
       " './data/data2022/SN104.edf',\n",
       " './data/data2022/SN104_sleepscoring.edf',\n",
       " './data/data2022/SN105.edf',\n",
       " './data/data2022/SN105_sleepscoring.edf',\n",
       " './data/data2022/SN106.edf',\n",
       " './data/data2022/SN106_sleepscoring.edf',\n",
       " './data/data2022/SN107.edf',\n",
       " './data/data2022/SN107_sleepscoring.edf',\n",
       " './data/data2022/SN108.edf',\n",
       " './data/data2022/SN108_sleepscoring.edf',\n",
       " './data/data2022/SN109.edf',\n",
       " './data/data2022/SN109_sleepscoring.edf',\n",
       " './data/data2022/SN110.edf',\n",
       " './data/data2022/SN110_sleepscoring.edf',\n",
       " './data/data2022/SN111.edf',\n",
       " './data/data2022/SN111_sleepscoring.edf',\n",
       " './data/data2022/SN112.edf',\n",
       " './data/data2022/SN112_sleepscoring.edf',\n",
       " './data/data2022/SN113.edf',\n",
       " './data/data2022/SN113_sleepscoring.edf',\n",
       " './data/data2022/SN114.edf',\n",
       " './data/data2022/SN114_sleepscoring.edf',\n",
       " './data/data2022/SN115.edf',\n",
       " './data/data2022/SN115_sleepscoring.edf',\n",
       " './data/data2022/SN116.edf',\n",
       " './data/data2022/SN116_sleepscoring.edf',\n",
       " './data/data2022/SN117.edf',\n",
       " './data/data2022/SN117_sleepscoring.edf',\n",
       " './data/data2022/SN118.edf',\n",
       " './data/data2022/SN118_sleepscoring.edf',\n",
       " './data/data2022/SN119.edf',\n",
       " './data/data2022/SN119_sleepscoring.edf',\n",
       " './data/data2022/SN120.edf',\n",
       " './data/data2022/SN120_sleepscoring.edf',\n",
       " './data/data2022/SN121.edf',\n",
       " './data/data2022/SN121_sleepscoring.edf',\n",
       " './data/data2022/SN122.edf',\n",
       " './data/data2022/SN122_sleepscoring.edf',\n",
       " './data/data2022/SN123.edf',\n",
       " './data/data2022/SN123_sleepscoring.edf',\n",
       " './data/data2022/SN124.edf',\n",
       " './data/data2022/SN124_sleepscoring.edf',\n",
       " './data/data2022/SN125.edf',\n",
       " './data/data2022/SN125_sleepscoring.edf',\n",
       " './data/data2022/SN126.edf',\n",
       " './data/data2022/SN126_sleepscoring.edf',\n",
       " './data/data2022/SN127.edf',\n",
       " './data/data2022/SN127_sleepscoring.edf',\n",
       " './data/data2022/SN128.edf',\n",
       " './data/data2022/SN128_sleepscoring.edf',\n",
       " './data/data2022/SN129.edf',\n",
       " './data/data2022/SN129_sleepscoring.edf',\n",
       " './data/data2022/SN130.edf',\n",
       " './data/data2022/SN130_sleepscoring.edf',\n",
       " './data/data2022/SN131.edf',\n",
       " './data/data2022/SN131_sleepscoring.edf',\n",
       " './data/data2022/SN132.edf',\n",
       " './data/data2022/SN132_sleepscoring.edf',\n",
       " './data/data2022/SN133.edf',\n",
       " './data/data2022/SN133_sleepscoring.edf',\n",
       " './data/data2022/SN134.edf',\n",
       " './data/data2022/SN134_sleepscoring.edf',\n",
       " './data/data2022/SN136.edf',\n",
       " './data/data2022/SN136_sleepscoring.edf',\n",
       " './data/data2022/SN137.edf',\n",
       " './data/data2022/SN137_sleepscoring.edf',\n",
       " './data/data2022/SN138.edf',\n",
       " './data/data2022/SN138_sleepscoring.edf',\n",
       " './data/data2022/SN139.edf',\n",
       " './data/data2022/SN139_sleepscoring.edf',\n",
       " './data/data2022/SN140.edf',\n",
       " './data/data2022/SN140_sleepscoring.edf',\n",
       " './data/data2022/SN141.edf',\n",
       " './data/data2022/SN141_sleepscoring.edf',\n",
       " './data/data2022/SN142.edf',\n",
       " './data/data2022/SN142_sleepscoring.edf',\n",
       " './data/data2022/SN143.edf',\n",
       " './data/data2022/SN143_sleepscoring.edf',\n",
       " './data/data2022/SN144.edf',\n",
       " './data/data2022/SN144_sleepscoring.edf',\n",
       " './data/data2022/SN145.edf',\n",
       " './data/data2022/SN145_sleepscoring.edf',\n",
       " './data/data2022/SN146.edf',\n",
       " './data/data2022/SN146_sleepscoring.edf',\n",
       " './data/data2022/SN147.edf',\n",
       " './data/data2022/SN147_sleepscoring.edf',\n",
       " './data/data2022/SN148.edf',\n",
       " './data/data2022/SN148_sleepscoring.edf',\n",
       " './data/data2022/SN149.edf',\n",
       " './data/data2022/SN149_sleepscoring.edf',\n",
       " './data/data2022/SN150.edf',\n",
       " './data/data2022/SN150_sleepscoring.edf',\n",
       " './data/data2022/SN151.edf',\n",
       " './data/data2022/SN151_sleepscoring.edf',\n",
       " './data/data2022/SN152.edf',\n",
       " './data/data2022/SN152_sleepscoring.edf',\n",
       " './data/data2022/SN153.edf',\n",
       " './data/data2022/SN153_sleepscoring.edf',\n",
       " './data/data2022/SN154.edf',\n",
       " './data/data2022/SN154_sleepscoring.edf']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyedflib import highlevel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "data_list=glob('./data/data2022/*.edf')\n",
    "\n",
    "# trains=[x for x in data_list if x.endswith('PSG.edf')]\n",
    "# labels=[x for x in data_list if x.endswith('Hypnogram.edf')]\n",
    "trains=[x for x in data_list if not x.endswith('_sleepscoring.edf')]\n",
    "labels=[x for x in data_list if x.endswith('_sleepscoring.edf')]\n",
    "\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "print(len(trains))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.71267262e+01,  1.82253758e+01,  1.75906004e+01, ...,\n",
       "         -1.22072175e-02, -1.22072175e-02, -1.22072175e-02],\n",
       "        [ 1.47585260e+01,  1.55642023e+01,  1.06324865e+01, ...,\n",
       "         -1.22072175e-02, -1.22072175e-02, -1.22072175e-02],\n",
       "        [ 3.83428702e+01,  3.71221485e+01,  2.41092546e+01, ...,\n",
       "         -1.22072175e-02, -1.22072175e-02, -1.22072175e-02],\n",
       "        ...,\n",
       "        [ 3.74761578e+00,  1.09987030e+01,  2.16433967e+01, ...,\n",
       "         -1.22072175e-02, -1.22072175e-02, -1.22072175e-02],\n",
       "        [-9.28969253e+00, -1.09010452e+01, -9.50942245e+00, ...,\n",
       "         -1.22072175e-02, -1.22072175e-02, -1.22072175e-02],\n",
       "        [ 7.37193866e+01,  7.09361410e+01,  6.93980316e+01, ...,\n",
       "         -3.66216526e-02, -3.66216526e-02, -3.66216526e-02]]),\n",
       " [{'label': 'EEG F4-M1',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:0.2Hz LP:35.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'EEG C4-M1',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:0.2Hz LP:35.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'EEG O2-M1',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:0.2Hz LP:35.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'EEG C3-M2',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:0.2Hz LP:35.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'EMG chin',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:1.0Hz LP:150.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'EOG E1-M2',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:0.2Hz LP:35.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'EOG E2-M2',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 800.0,\n",
       "   'physical_min': -800.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:0.2Hz LP:35.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'},\n",
       "  {'label': 'ECG',\n",
       "   'dimension': 'uV',\n",
       "   'sample_rate': 256.0,\n",
       "   'sample_frequency': 256.0,\n",
       "   'physical_max': 2400.0,\n",
       "   'physical_min': -2400.0,\n",
       "   'digital_max': 32767,\n",
       "   'digital_min': -32768,\n",
       "   'prefilter': 'HP:1.0Hz LP:150.0Hz',\n",
       "   'transducer': 'AgAgCl electrodes'}],\n",
       " {'technician': '',\n",
       "  'recording_additional': '',\n",
       "  'patientname': '',\n",
       "  'patient_additional': '',\n",
       "  'patientcode': '',\n",
       "  'equipment': '',\n",
       "  'admincode': '',\n",
       "  'sex': '',\n",
       "  'startdate': datetime.datetime(2001, 1, 1, 23, 59, 30),\n",
       "  'birthdate': '',\n",
       "  'gender': '',\n",
       "  'annotations': []})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlevel.read_edf(trains[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 8 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/home/GoodSleep/test.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/home/GoodSleep/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(highlevel\u001b[39m.\u001b[39mread_edf(trains[\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mT\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/home/GoodSleep/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39;49mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mEEG Fpz-Cz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEEG Pz-Oz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEOG horizontal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mResp oro-nassal\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/home/GoodSleep/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mEMG submental\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTemp rectal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEvent marker\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/home/GoodSleep/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df\n",
      "File \u001b[0;32m~/anaconda3/envs/gs/lib/python3.10/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   6219\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gs/lib/python3.10/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    768\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/gs/lib/python3.10/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/envs/gs/lib/python3.10/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 8 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(highlevel.read_edf(trains[0])[0]).T\n",
    "df.columns = ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nassal',\n",
    "              'EMG submental', 'Temp rectal', 'Event marker']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64),\n",
       " [],\n",
       " {'technician': '',\n",
       "  'recording_additional': '',\n",
       "  'patientname': 'X',\n",
       "  'patient_additional': '',\n",
       "  'patientcode': 'SN001',\n",
       "  'equipment': '',\n",
       "  'admincode': '',\n",
       "  'sex': '',\n",
       "  'startdate': datetime.datetime(2001, 1, 1, 23, 59, 30),\n",
       "  'birthdate': '',\n",
       "  'gender': '',\n",
       "  'annotations': [[0.0, 30.0, 'Sleep stage W'],\n",
       "   [30.0, 30.0, 'Sleep stage W'],\n",
       "   [33.43, 0.0, 'Lights off@@EEG F4-A1'],\n",
       "   [60.0, 30.0, 'Sleep stage W'],\n",
       "   [90.0, 30.0, 'Sleep stage W'],\n",
       "   [120.0, 30.0, 'Sleep stage W'],\n",
       "   [150.0, 30.0, 'Sleep stage W'],\n",
       "   [180.0, 30.0, 'Sleep stage W'],\n",
       "   [210.0, 30.0, 'Sleep stage W'],\n",
       "   [240.0, 30.0, 'Sleep stage N1'],\n",
       "   [270.0, 30.0, 'Sleep stage N1'],\n",
       "   [300.0, 30.0, 'Sleep stage N1'],\n",
       "   [330.0, 30.0, 'Sleep stage N1'],\n",
       "   [360.0, 30.0, 'Sleep stage N1'],\n",
       "   [390.0, 30.0, 'Sleep stage N1'],\n",
       "   [420.0, 30.0, 'Sleep stage N1'],\n",
       "   [450.0, 30.0, 'Sleep stage N1'],\n",
       "   [480.0, 30.0, 'Sleep stage N2'],\n",
       "   [510.0, 30.0, 'Sleep stage N1'],\n",
       "   [540.0, 30.0, 'Sleep stage N2'],\n",
       "   [570.0, 30.0, 'Sleep stage N2'],\n",
       "   [600.0, 30.0, 'Sleep stage N2'],\n",
       "   [630.0, 30.0, 'Sleep stage N2'],\n",
       "   [660.0, 30.0, 'Sleep stage N2'],\n",
       "   [690.0, 30.0, 'Sleep stage N2'],\n",
       "   [720.0, 30.0, 'Sleep stage N1'],\n",
       "   [750.0, 30.0, 'Sleep stage N1'],\n",
       "   [780.0, 30.0, 'Sleep stage W'],\n",
       "   [810.0, 30.0, 'Sleep stage N1'],\n",
       "   [840.0, 30.0, 'Sleep stage N1'],\n",
       "   [870.0, 30.0, 'Sleep stage N1'],\n",
       "   [900.0, 30.0, 'Sleep stage N1'],\n",
       "   [930.0, 30.0, 'Sleep stage N1'],\n",
       "   [960.0, 30.0, 'Sleep stage N1'],\n",
       "   [990.0, 30.0, 'Sleep stage N2'],\n",
       "   [1020.0, 30.0, 'Sleep stage N1'],\n",
       "   [1050.0, 30.0, 'Sleep stage W'],\n",
       "   [1080.0, 30.0, 'Sleep stage W'],\n",
       "   [1110.0, 30.0, 'Sleep stage W'],\n",
       "   [1140.0, 30.0, 'Sleep stage W'],\n",
       "   [1170.0, 30.0, 'Sleep stage N1'],\n",
       "   [1200.0, 30.0, 'Sleep stage N1'],\n",
       "   [1230.0, 30.0, 'Sleep stage N1'],\n",
       "   [1260.0, 30.0, 'Sleep stage N1'],\n",
       "   [1290.0, 30.0, 'Sleep stage N1'],\n",
       "   [1320.0, 30.0, 'Sleep stage N1'],\n",
       "   [1350.0, 30.0, 'Sleep stage N1'],\n",
       "   [1380.0, 30.0, 'Sleep stage N1'],\n",
       "   [1410.0, 30.0, 'Sleep stage N1'],\n",
       "   [1440.0, 30.0, 'Sleep stage N1'],\n",
       "   [1470.0, 30.0, 'Sleep stage N1'],\n",
       "   [1500.0, 30.0, 'Sleep stage N1'],\n",
       "   [1530.0, 30.0, 'Sleep stage N2'],\n",
       "   [1560.0, 30.0, 'Sleep stage N2'],\n",
       "   [1590.0, 30.0, 'Sleep stage N2'],\n",
       "   [1620.0, 30.0, 'Sleep stage N2'],\n",
       "   [1650.0, 30.0, 'Sleep stage N2'],\n",
       "   [1680.0, 30.0, 'Sleep stage N2'],\n",
       "   [1710.0, 30.0, 'Sleep stage N2'],\n",
       "   [1740.0, 30.0, 'Sleep stage N2'],\n",
       "   [1770.0, 30.0, 'Sleep stage N2'],\n",
       "   [1800.0, 30.0, 'Sleep stage N2'],\n",
       "   [1830.0, 30.0, 'Sleep stage N2'],\n",
       "   [1860.0, 30.0, 'Sleep stage N2'],\n",
       "   [1890.0, 30.0, 'Sleep stage N2'],\n",
       "   [1920.0, 30.0, 'Sleep stage N2'],\n",
       "   [1950.0, 30.0, 'Sleep stage N2'],\n",
       "   [1980.0, 30.0, 'Sleep stage N2'],\n",
       "   [2010.0, 30.0, 'Sleep stage N2'],\n",
       "   [2040.0, 30.0, 'Sleep stage N2'],\n",
       "   [2070.0, 30.0, 'Sleep stage N2'],\n",
       "   [2100.0, 30.0, 'Sleep stage N2'],\n",
       "   [2130.0, 30.0, 'Sleep stage N2'],\n",
       "   [2160.0, 30.0, 'Sleep stage N2'],\n",
       "   [2190.0, 30.0, 'Sleep stage N2'],\n",
       "   [2220.0, 30.0, 'Sleep stage N2'],\n",
       "   [2250.0, 30.0, 'Sleep stage N2'],\n",
       "   [2280.0, 30.0, 'Sleep stage N2'],\n",
       "   [2310.0, 30.0, 'Sleep stage N2'],\n",
       "   [2340.0, 30.0, 'Sleep stage N2'],\n",
       "   [2370.0, 30.0, 'Sleep stage N2'],\n",
       "   [2400.0, 30.0, 'Sleep stage N2'],\n",
       "   [2430.0, 30.0, 'Sleep stage N2'],\n",
       "   [2460.0, 30.0, 'Sleep stage N1'],\n",
       "   [2490.0, 30.0, 'Sleep stage N2'],\n",
       "   [2520.0, 30.0, 'Sleep stage N2'],\n",
       "   [2550.0, 30.0, 'Sleep stage N2'],\n",
       "   [2580.0, 30.0, 'Sleep stage N2'],\n",
       "   [2610.0, 30.0, 'Sleep stage N2'],\n",
       "   [2640.0, 30.0, 'Sleep stage N2'],\n",
       "   [2670.0, 30.0, 'Sleep stage N2'],\n",
       "   [2700.0, 30.0, 'Sleep stage N2'],\n",
       "   [2730.0, 30.0, 'Sleep stage N2'],\n",
       "   [2760.0, 30.0, 'Sleep stage N2'],\n",
       "   [2790.0, 30.0, 'Sleep stage N2'],\n",
       "   [2820.0, 30.0, 'Sleep stage N2'],\n",
       "   [2850.0, 30.0, 'Sleep stage N2'],\n",
       "   [2880.0, 30.0, 'Sleep stage N2'],\n",
       "   [2910.0, 30.0, 'Sleep stage N2'],\n",
       "   [2940.0, 30.0, 'Sleep stage N2'],\n",
       "   [2970.0, 30.0, 'Sleep stage N2'],\n",
       "   [3000.0, 30.0, 'Sleep stage N2'],\n",
       "   [3030.0, 30.0, 'Sleep stage N2'],\n",
       "   [3060.0, 30.0, 'Sleep stage N2'],\n",
       "   [3090.0, 30.0, 'Sleep stage N2'],\n",
       "   [3120.0, 30.0, 'Sleep stage N2'],\n",
       "   [3150.0, 30.0, 'Sleep stage N3'],\n",
       "   [3180.0, 30.0, 'Sleep stage N3'],\n",
       "   [3210.0, 30.0, 'Sleep stage N2'],\n",
       "   [3240.0, 30.0, 'Sleep stage N3'],\n",
       "   [3270.0, 30.0, 'Sleep stage N3'],\n",
       "   [3300.0, 30.0, 'Sleep stage N2'],\n",
       "   [3330.0, 30.0, 'Sleep stage N3'],\n",
       "   [3360.0, 30.0, 'Sleep stage N3'],\n",
       "   [3390.0, 30.0, 'Sleep stage N3'],\n",
       "   [3420.0, 30.0, 'Sleep stage N3'],\n",
       "   [3450.0, 30.0, 'Sleep stage N3'],\n",
       "   [3480.0, 30.0, 'Sleep stage N3'],\n",
       "   [3510.0, 30.0, 'Sleep stage N2'],\n",
       "   [3540.0, 30.0, 'Sleep stage N3'],\n",
       "   [3570.0, 30.0, 'Sleep stage N3'],\n",
       "   [3600.0, 30.0, 'Sleep stage N2'],\n",
       "   [3630.0, 30.0, 'Sleep stage N3'],\n",
       "   [3660.0, 30.0, 'Sleep stage N2'],\n",
       "   [3690.0, 30.0, 'Sleep stage N2'],\n",
       "   [3720.0, 30.0, 'Sleep stage N2'],\n",
       "   [3750.0, 30.0, 'Sleep stage N2'],\n",
       "   [3780.0, 30.0, 'Sleep stage N2'],\n",
       "   [3810.0, 30.0, 'Sleep stage N2'],\n",
       "   [3840.0, 30.0, 'Sleep stage N2'],\n",
       "   [3870.0, 30.0, 'Sleep stage N2'],\n",
       "   [3900.0, 30.0, 'Sleep stage N2'],\n",
       "   [3930.0, 30.0, 'Sleep stage N2'],\n",
       "   [3960.0, 30.0, 'Sleep stage N2'],\n",
       "   [3990.0, 30.0, 'Sleep stage N2'],\n",
       "   [4020.0, 30.0, 'Sleep stage N2'],\n",
       "   [4050.0, 30.0, 'Sleep stage N2'],\n",
       "   [4080.0, 30.0, 'Sleep stage N2'],\n",
       "   [4110.0, 30.0, 'Sleep stage N2'],\n",
       "   [4140.0, 30.0, 'Sleep stage N2'],\n",
       "   [4170.0, 30.0, 'Sleep stage N2'],\n",
       "   [4200.0, 30.0, 'Sleep stage N1'],\n",
       "   [4230.0, 30.0, 'Sleep stage N2'],\n",
       "   [4260.0, 30.0, 'Sleep stage N2'],\n",
       "   [4290.0, 30.0, 'Sleep stage N2'],\n",
       "   [4320.0, 30.0, 'Sleep stage N2'],\n",
       "   [4350.0, 30.0, 'Sleep stage N2'],\n",
       "   [4380.0, 30.0, 'Sleep stage N2'],\n",
       "   [4410.0, 30.0, 'Sleep stage N2'],\n",
       "   [4440.0, 30.0, 'Sleep stage N1'],\n",
       "   [4470.0, 30.0, 'Sleep stage N2'],\n",
       "   [4500.0, 30.0, 'Sleep stage N2'],\n",
       "   [4530.0, 30.0, 'Sleep stage N2'],\n",
       "   [4560.0, 30.0, 'Sleep stage N2'],\n",
       "   [4590.0, 30.0, 'Sleep stage N1'],\n",
       "   [4620.0, 30.0, 'Sleep stage N2'],\n",
       "   [4650.0, 30.0, 'Sleep stage R'],\n",
       "   [4680.0, 30.0, 'Sleep stage R'],\n",
       "   [4710.0, 30.0, 'Sleep stage R'],\n",
       "   [4740.0, 30.0, 'Sleep stage R'],\n",
       "   [4770.0, 30.0, 'Sleep stage R'],\n",
       "   [4800.0, 30.0, 'Sleep stage R'],\n",
       "   [4830.0, 30.0, 'Sleep stage R'],\n",
       "   [4860.0, 30.0, 'Sleep stage R'],\n",
       "   [4890.0, 30.0, 'Sleep stage R'],\n",
       "   [4920.0, 30.0, 'Sleep stage R'],\n",
       "   [4950.0, 30.0, 'Sleep stage R'],\n",
       "   [4980.0, 30.0, 'Sleep stage R'],\n",
       "   [5010.0, 30.0, 'Sleep stage R'],\n",
       "   [5040.0, 30.0, 'Sleep stage R'],\n",
       "   [5070.0, 30.0, 'Sleep stage R'],\n",
       "   [5100.0, 30.0, 'Sleep stage R'],\n",
       "   [5130.0, 30.0, 'Sleep stage R'],\n",
       "   [5160.0, 30.0, 'Sleep stage R'],\n",
       "   [5190.0, 30.0, 'Sleep stage N1'],\n",
       "   [5220.0, 30.0, 'Sleep stage R'],\n",
       "   [5250.0, 30.0, 'Sleep stage R'],\n",
       "   [5280.0, 30.0, 'Sleep stage R'],\n",
       "   [5310.0, 30.0, 'Sleep stage R'],\n",
       "   [5340.0, 30.0, 'Sleep stage R'],\n",
       "   [5370.0, 30.0, 'Sleep stage R'],\n",
       "   [5400.0, 30.0, 'Sleep stage W'],\n",
       "   [5430.0, 30.0, 'Sleep stage W'],\n",
       "   [5460.0, 30.0, 'Sleep stage W'],\n",
       "   [5490.0, 30.0, 'Sleep stage W'],\n",
       "   [5520.0, 30.0, 'Sleep stage W'],\n",
       "   [5550.0, 30.0, 'Sleep stage W'],\n",
       "   [5580.0, 30.0, 'Sleep stage W'],\n",
       "   [5610.0, 30.0, 'Sleep stage W'],\n",
       "   [5640.0, 30.0, 'Sleep stage W'],\n",
       "   [5670.0, 30.0, 'Sleep stage W'],\n",
       "   [5700.0, 30.0, 'Sleep stage W'],\n",
       "   [5730.0, 30.0, 'Sleep stage W'],\n",
       "   [5760.0, 30.0, 'Sleep stage N1'],\n",
       "   [5790.0, 30.0, 'Sleep stage N1'],\n",
       "   [5820.0, 30.0, 'Sleep stage N1'],\n",
       "   [5850.0, 30.0, 'Sleep stage N1'],\n",
       "   [5880.0, 30.0, 'Sleep stage N1'],\n",
       "   [5910.0, 30.0, 'Sleep stage N1'],\n",
       "   [5940.0, 30.0, 'Sleep stage N2'],\n",
       "   [5970.0, 30.0, 'Sleep stage N2'],\n",
       "   [6000.0, 30.0, 'Sleep stage N2'],\n",
       "   [6030.0, 30.0, 'Sleep stage N2'],\n",
       "   [6060.0, 30.0, 'Sleep stage N1'],\n",
       "   [6090.0, 30.0, 'Sleep stage N1'],\n",
       "   [6120.0, 30.0, 'Sleep stage N2'],\n",
       "   [6150.0, 30.0, 'Sleep stage N2'],\n",
       "   [6180.0, 30.0, 'Sleep stage N2'],\n",
       "   [6210.0, 30.0, 'Sleep stage N2'],\n",
       "   [6240.0, 30.0, 'Sleep stage N2'],\n",
       "   [6270.0, 30.0, 'Sleep stage N2'],\n",
       "   [6300.0, 30.0, 'Sleep stage N2'],\n",
       "   [6330.0, 30.0, 'Sleep stage N2'],\n",
       "   [6360.0, 30.0, 'Sleep stage N2'],\n",
       "   [6390.0, 30.0, 'Sleep stage N2'],\n",
       "   [6420.0, 30.0, 'Sleep stage N2'],\n",
       "   [6450.0, 30.0, 'Sleep stage N2'],\n",
       "   [6480.0, 30.0, 'Sleep stage N2'],\n",
       "   [6510.0, 30.0, 'Sleep stage N2'],\n",
       "   [6540.0, 30.0, 'Sleep stage N2'],\n",
       "   [6570.0, 30.0, 'Sleep stage N2'],\n",
       "   [6600.0, 30.0, 'Sleep stage N2'],\n",
       "   [6630.0, 30.0, 'Sleep stage N2'],\n",
       "   [6660.0, 30.0, 'Sleep stage N2'],\n",
       "   [6690.0, 30.0, 'Sleep stage N2'],\n",
       "   [6720.0, 30.0, 'Sleep stage N2'],\n",
       "   [6750.0, 30.0, 'Sleep stage N2'],\n",
       "   [6780.0, 30.0, 'Sleep stage N2'],\n",
       "   [6810.0, 30.0, 'Sleep stage N2'],\n",
       "   [6840.0, 30.0, 'Sleep stage N2'],\n",
       "   [6870.0, 30.0, 'Sleep stage N2'],\n",
       "   [6900.0, 30.0, 'Sleep stage N2'],\n",
       "   [6930.0, 30.0, 'Sleep stage N2'],\n",
       "   [6960.0, 30.0, 'Sleep stage N2'],\n",
       "   [6990.0, 30.0, 'Sleep stage N2'],\n",
       "   [7020.0, 30.0, 'Sleep stage N2'],\n",
       "   [7050.0, 30.0, 'Sleep stage N2'],\n",
       "   [7080.0, 30.0, 'Sleep stage N2'],\n",
       "   [7110.0, 30.0, 'Sleep stage N2'],\n",
       "   [7140.0, 30.0, 'Sleep stage N2'],\n",
       "   [7170.0, 30.0, 'Sleep stage N2'],\n",
       "   [7200.0, 30.0, 'Sleep stage N1'],\n",
       "   [7230.0, 30.0, 'Sleep stage N1'],\n",
       "   [7260.0, 30.0, 'Sleep stage N1'],\n",
       "   [7290.0, 30.0, 'Sleep stage N1'],\n",
       "   [7320.0, 30.0, 'Sleep stage N1'],\n",
       "   [7350.0, 30.0, 'Sleep stage N1'],\n",
       "   [7380.0, 30.0, 'Sleep stage N1'],\n",
       "   [7410.0, 30.0, 'Sleep stage W'],\n",
       "   [7440.0, 30.0, 'Sleep stage N1'],\n",
       "   [7470.0, 30.0, 'Sleep stage N1'],\n",
       "   [7500.0, 30.0, 'Sleep stage N1'],\n",
       "   [7530.0, 30.0, 'Sleep stage N1'],\n",
       "   [7560.0, 30.0, 'Sleep stage N1'],\n",
       "   [7590.0, 30.0, 'Sleep stage N2'],\n",
       "   [7620.0, 30.0, 'Sleep stage N2'],\n",
       "   [7650.0, 30.0, 'Sleep stage N2'],\n",
       "   [7680.0, 30.0, 'Sleep stage N2'],\n",
       "   [7710.0, 30.0, 'Sleep stage N2'],\n",
       "   [7740.0, 30.0, 'Sleep stage N2'],\n",
       "   [7770.0, 30.0, 'Sleep stage N2'],\n",
       "   [7800.0, 30.0, 'Sleep stage N2'],\n",
       "   [7830.0, 30.0, 'Sleep stage N2'],\n",
       "   [7860.0, 30.0, 'Sleep stage N2'],\n",
       "   [7890.0, 30.0, 'Sleep stage N2'],\n",
       "   [7920.0, 30.0, 'Sleep stage N2'],\n",
       "   [7950.0, 30.0, 'Sleep stage N2'],\n",
       "   [7980.0, 30.0, 'Sleep stage N2'],\n",
       "   [8010.0, 30.0, 'Sleep stage N2'],\n",
       "   [8040.0, 30.0, 'Sleep stage N2'],\n",
       "   [8070.0, 30.0, 'Sleep stage N2'],\n",
       "   [8100.0, 30.0, 'Sleep stage N2'],\n",
       "   [8130.0, 30.0, 'Sleep stage N2'],\n",
       "   [8160.0, 30.0, 'Sleep stage N2'],\n",
       "   [8190.0, 30.0, 'Sleep stage N2'],\n",
       "   [8220.0, 30.0, 'Sleep stage N2'],\n",
       "   [8250.0, 30.0, 'Sleep stage N2'],\n",
       "   [8280.0, 30.0, 'Sleep stage N2'],\n",
       "   [8310.0, 30.0, 'Sleep stage N1'],\n",
       "   [8340.0, 30.0, 'Sleep stage N2'],\n",
       "   [8370.0, 30.0, 'Sleep stage N2'],\n",
       "   [8400.0, 30.0, 'Sleep stage N2'],\n",
       "   [8430.0, 30.0, 'Sleep stage N2'],\n",
       "   [8460.0, 30.0, 'Sleep stage N2'],\n",
       "   [8490.0, 30.0, 'Sleep stage N2'],\n",
       "   [8520.0, 30.0, 'Sleep stage N2'],\n",
       "   [8550.0, 30.0, 'Sleep stage N2'],\n",
       "   [8580.0, 30.0, 'Sleep stage N2'],\n",
       "   [8610.0, 30.0, 'Sleep stage N2'],\n",
       "   [8640.0, 30.0, 'Sleep stage N1'],\n",
       "   [8670.0, 30.0, 'Sleep stage N2'],\n",
       "   [8700.0, 30.0, 'Sleep stage N2'],\n",
       "   [8730.0, 30.0, 'Sleep stage N2'],\n",
       "   [8760.0, 30.0, 'Sleep stage N2'],\n",
       "   [8790.0, 30.0, 'Sleep stage N2'],\n",
       "   [8820.0, 30.0, 'Sleep stage N2'],\n",
       "   [8850.0, 30.0, 'Sleep stage N2'],\n",
       "   [8880.0, 30.0, 'Sleep stage N2'],\n",
       "   [8910.0, 30.0, 'Sleep stage N2'],\n",
       "   [8940.0, 30.0, 'Sleep stage N2'],\n",
       "   [8970.0, 30.0, 'Sleep stage N2'],\n",
       "   [9000.0, 30.0, 'Sleep stage N1'],\n",
       "   [9030.0, 30.0, 'Sleep stage N2'],\n",
       "   [9060.0, 30.0, 'Sleep stage N2'],\n",
       "   [9090.0, 30.0, 'Sleep stage N2'],\n",
       "   [9120.0, 30.0, 'Sleep stage N2'],\n",
       "   [9150.0, 30.0, 'Sleep stage N2'],\n",
       "   [9180.0, 30.0, 'Sleep stage N2'],\n",
       "   [9210.0, 30.0, 'Sleep stage N2'],\n",
       "   [9240.0, 30.0, 'Sleep stage N2'],\n",
       "   [9270.0, 30.0, 'Sleep stage N2'],\n",
       "   [9300.0, 30.0, 'Sleep stage N2'],\n",
       "   [9330.0, 30.0, 'Sleep stage N2'],\n",
       "   [9360.0, 30.0, 'Sleep stage N2'],\n",
       "   [9390.0, 30.0, 'Sleep stage R'],\n",
       "   [9420.0, 30.0, 'Sleep stage N2'],\n",
       "   [9450.0, 30.0, 'Sleep stage R'],\n",
       "   [9480.0, 30.0, 'Sleep stage N1'],\n",
       "   [9510.0, 30.0, 'Sleep stage W'],\n",
       "   [9540.0, 30.0, 'Sleep stage W'],\n",
       "   [9570.0, 30.0, 'Sleep stage W'],\n",
       "   [9600.0, 30.0, 'Sleep stage W'],\n",
       "   [9630.0, 30.0, 'Sleep stage W'],\n",
       "   [9660.0, 30.0, 'Sleep stage W'],\n",
       "   [9690.0, 30.0, 'Sleep stage W'],\n",
       "   [9720.0, 30.0, 'Sleep stage W'],\n",
       "   [9750.0, 30.0, 'Sleep stage W'],\n",
       "   [9780.0, 30.0, 'Sleep stage W'],\n",
       "   [9810.0, 30.0, 'Sleep stage W'],\n",
       "   [9840.0, 30.0, 'Sleep stage W'],\n",
       "   [9870.0, 30.0, 'Sleep stage W'],\n",
       "   [9900.0, 30.0, 'Sleep stage W'],\n",
       "   [9930.0, 30.0, 'Sleep stage W'],\n",
       "   [9960.0, 30.0, 'Sleep stage W'],\n",
       "   [9990.0, 30.0, 'Sleep stage W'],\n",
       "   [10020.0, 30.0, 'Sleep stage W'],\n",
       "   [10050.0, 30.0, 'Sleep stage W'],\n",
       "   [10080.0, 30.0, 'Sleep stage W'],\n",
       "   [10110.0, 30.0, 'Sleep stage W'],\n",
       "   [10140.0, 30.0, 'Sleep stage W'],\n",
       "   [10170.0, 30.0, 'Sleep stage W'],\n",
       "   [10200.0, 30.0, 'Sleep stage W'],\n",
       "   [10230.0, 30.0, 'Sleep stage W'],\n",
       "   [10260.0, 30.0, 'Sleep stage W'],\n",
       "   [10290.0, 30.0, 'Sleep stage W'],\n",
       "   [10320.0, 30.0, 'Sleep stage W'],\n",
       "   [10350.0, 30.0, 'Sleep stage W'],\n",
       "   [10380.0, 30.0, 'Sleep stage W'],\n",
       "   [10410.0, 30.0, 'Sleep stage W'],\n",
       "   [10440.0, 30.0, 'Sleep stage W'],\n",
       "   [10470.0, 30.0, 'Sleep stage W'],\n",
       "   [10500.0, 30.0, 'Sleep stage W'],\n",
       "   [10530.0, 30.0, 'Sleep stage W'],\n",
       "   [10560.0, 30.0, 'Sleep stage W'],\n",
       "   [10590.0, 30.0, 'Sleep stage W'],\n",
       "   [10620.0, 30.0, 'Sleep stage W'],\n",
       "   [10650.0, 30.0, 'Sleep stage W'],\n",
       "   [10680.0, 30.0, 'Sleep stage W'],\n",
       "   [10710.0, 30.0, 'Sleep stage W'],\n",
       "   [10740.0, 30.0, 'Sleep stage W'],\n",
       "   [10770.0, 30.0, 'Sleep stage W'],\n",
       "   [10800.0, 30.0, 'Sleep stage W'],\n",
       "   [10830.0, 30.0, 'Sleep stage W'],\n",
       "   [10860.0, 30.0, 'Sleep stage W'],\n",
       "   [10890.0, 30.0, 'Sleep stage W'],\n",
       "   [10920.0, 30.0, 'Sleep stage W'],\n",
       "   [10950.0, 30.0, 'Sleep stage W'],\n",
       "   [10980.0, 30.0, 'Sleep stage W'],\n",
       "   [11010.0, 30.0, 'Sleep stage W'],\n",
       "   [11040.0, 30.0, 'Sleep stage W'],\n",
       "   [11070.0, 30.0, 'Sleep stage W'],\n",
       "   [11100.0, 30.0, 'Sleep stage W'],\n",
       "   [11130.0, 30.0, 'Sleep stage W'],\n",
       "   [11160.0, 30.0, 'Sleep stage W'],\n",
       "   [11190.0, 30.0, 'Sleep stage W'],\n",
       "   [11220.0, 30.0, 'Sleep stage W'],\n",
       "   [11250.0, 30.0, 'Sleep stage W'],\n",
       "   [11280.0, 30.0, 'Sleep stage W'],\n",
       "   [11310.0, 30.0, 'Sleep stage W'],\n",
       "   [11340.0, 30.0, 'Sleep stage W'],\n",
       "   [11370.0, 30.0, 'Sleep stage W'],\n",
       "   [11400.0, 30.0, 'Sleep stage W'],\n",
       "   [11430.0, 30.0, 'Sleep stage W'],\n",
       "   [11460.0, 30.0, 'Sleep stage W'],\n",
       "   [11490.0, 30.0, 'Sleep stage W'],\n",
       "   [11520.0, 30.0, 'Sleep stage W'],\n",
       "   [11550.0, 30.0, 'Sleep stage W'],\n",
       "   [11580.0, 30.0, 'Sleep stage W'],\n",
       "   [11610.0, 30.0, 'Sleep stage W'],\n",
       "   [11640.0, 30.0, 'Sleep stage W'],\n",
       "   [11670.0, 30.0, 'Sleep stage W'],\n",
       "   [11700.0, 30.0, 'Sleep stage W'],\n",
       "   [11730.0, 30.0, 'Sleep stage W'],\n",
       "   [11760.0, 30.0, 'Sleep stage W'],\n",
       "   [11790.0, 30.0, 'Sleep stage W'],\n",
       "   [11820.0, 30.0, 'Sleep stage W'],\n",
       "   [11850.0, 30.0, 'Sleep stage W'],\n",
       "   [11880.0, 30.0, 'Sleep stage W'],\n",
       "   [11910.0, 30.0, 'Sleep stage W'],\n",
       "   [11940.0, 30.0, 'Sleep stage W'],\n",
       "   [11970.0, 30.0, 'Sleep stage W'],\n",
       "   [12000.0, 30.0, 'Sleep stage W'],\n",
       "   [12030.0, 30.0, 'Sleep stage N1'],\n",
       "   [12060.0, 30.0, 'Sleep stage W'],\n",
       "   [12090.0, 30.0, 'Sleep stage N1'],\n",
       "   [12120.0, 30.0, 'Sleep stage W'],\n",
       "   [12150.0, 30.0, 'Sleep stage W'],\n",
       "   [12180.0, 30.0, 'Sleep stage N1'],\n",
       "   [12210.0, 30.0, 'Sleep stage N1'],\n",
       "   [12240.0, 30.0, 'Sleep stage N1'],\n",
       "   [12270.0, 30.0, 'Sleep stage N1'],\n",
       "   [12300.0, 30.0, 'Sleep stage N1'],\n",
       "   [12330.0, 30.0, 'Sleep stage N1'],\n",
       "   [12360.0, 30.0, 'Sleep stage N1'],\n",
       "   [12390.0, 30.0, 'Sleep stage N1'],\n",
       "   [12420.0, 30.0, 'Sleep stage N2'],\n",
       "   [12450.0, 30.0, 'Sleep stage N2'],\n",
       "   [12480.0, 30.0, 'Sleep stage N2'],\n",
       "   [12510.0, 30.0, 'Sleep stage N2'],\n",
       "   [12540.0, 30.0, 'Sleep stage N2'],\n",
       "   [12570.0, 30.0, 'Sleep stage N2'],\n",
       "   [12600.0, 30.0, 'Sleep stage N2'],\n",
       "   [12630.0, 30.0, 'Sleep stage N2'],\n",
       "   [12660.0, 30.0, 'Sleep stage N2'],\n",
       "   [12690.0, 30.0, 'Sleep stage N2'],\n",
       "   [12720.0, 30.0, 'Sleep stage N2'],\n",
       "   [12750.0, 30.0, 'Sleep stage N2'],\n",
       "   [12780.0, 30.0, 'Sleep stage N2'],\n",
       "   [12810.0, 30.0, 'Sleep stage N2'],\n",
       "   [12840.0, 30.0, 'Sleep stage N1'],\n",
       "   [12870.0, 30.0, 'Sleep stage N2'],\n",
       "   [12900.0, 30.0, 'Sleep stage N2'],\n",
       "   [12930.0, 30.0, 'Sleep stage N2'],\n",
       "   [12960.0, 30.0, 'Sleep stage N2'],\n",
       "   [12990.0, 30.0, 'Sleep stage N2'],\n",
       "   [13020.0, 30.0, 'Sleep stage N2'],\n",
       "   [13050.0, 30.0, 'Sleep stage N2'],\n",
       "   [13080.0, 30.0, 'Sleep stage N2'],\n",
       "   [13110.0, 30.0, 'Sleep stage N2'],\n",
       "   [13140.0, 30.0, 'Sleep stage N2'],\n",
       "   [13170.0, 30.0, 'Sleep stage N2'],\n",
       "   [13200.0, 30.0, 'Sleep stage N2'],\n",
       "   [13230.0, 30.0, 'Sleep stage N1'],\n",
       "   [13260.0, 30.0, 'Sleep stage N2'],\n",
       "   [13290.0, 30.0, 'Sleep stage N2'],\n",
       "   [13320.0, 30.0, 'Sleep stage N2'],\n",
       "   [13350.0, 30.0, 'Sleep stage N2'],\n",
       "   [13380.0, 30.0, 'Sleep stage N2'],\n",
       "   [13410.0, 30.0, 'Sleep stage N2'],\n",
       "   [13440.0, 30.0, 'Sleep stage N2'],\n",
       "   [13470.0, 30.0, 'Sleep stage N2'],\n",
       "   [13500.0, 30.0, 'Sleep stage N2'],\n",
       "   [13530.0, 30.0, 'Sleep stage N2'],\n",
       "   [13560.0, 30.0, 'Sleep stage N2'],\n",
       "   [13590.0, 30.0, 'Sleep stage N2'],\n",
       "   [13620.0, 30.0, 'Sleep stage N2'],\n",
       "   [13650.0, 30.0, 'Sleep stage N2'],\n",
       "   [13680.0, 30.0, 'Sleep stage N2'],\n",
       "   [13710.0, 30.0, 'Sleep stage N2'],\n",
       "   [13740.0, 30.0, 'Sleep stage N2'],\n",
       "   [13770.0, 30.0, 'Sleep stage N2'],\n",
       "   [13800.0, 30.0, 'Sleep stage N2'],\n",
       "   [13830.0, 30.0, 'Sleep stage N2'],\n",
       "   [13860.0, 30.0, 'Sleep stage N2'],\n",
       "   [13890.0, 30.0, 'Sleep stage N2'],\n",
       "   [13920.0, 30.0, 'Sleep stage N2'],\n",
       "   [13950.0, 30.0, 'Sleep stage N3'],\n",
       "   [13980.0, 30.0, 'Sleep stage N3'],\n",
       "   [14010.0, 30.0, 'Sleep stage N3'],\n",
       "   [14040.0, 30.0, 'Sleep stage N3'],\n",
       "   [14070.0, 30.0, 'Sleep stage N3'],\n",
       "   [14100.0, 30.0, 'Sleep stage N2'],\n",
       "   [14130.0, 30.0, 'Sleep stage N2'],\n",
       "   [14160.0, 30.0, 'Sleep stage N2'],\n",
       "   [14190.0, 30.0, 'Sleep stage N2'],\n",
       "   [14220.0, 30.0, 'Sleep stage N2'],\n",
       "   [14250.0, 30.0, 'Sleep stage N2'],\n",
       "   [14280.0, 30.0, 'Sleep stage N2'],\n",
       "   [14310.0, 30.0, 'Sleep stage N1'],\n",
       "   [14340.0, 30.0, 'Sleep stage N2'],\n",
       "   [14370.0, 30.0, 'Sleep stage N2'],\n",
       "   [14400.0, 30.0, 'Sleep stage N2'],\n",
       "   [14430.0, 30.0, 'Sleep stage N2'],\n",
       "   [14460.0, 30.0, 'Sleep stage N2'],\n",
       "   [14490.0, 30.0, 'Sleep stage N2'],\n",
       "   [14520.0, 30.0, 'Sleep stage N2'],\n",
       "   [14550.0, 30.0, 'Sleep stage N2'],\n",
       "   [14580.0, 30.0, 'Sleep stage N2'],\n",
       "   [14610.0, 30.0, 'Sleep stage N2'],\n",
       "   [14640.0, 30.0, 'Sleep stage N2'],\n",
       "   [14670.0, 30.0, 'Sleep stage N2'],\n",
       "   [14700.0, 30.0, 'Sleep stage N2'],\n",
       "   [14730.0, 30.0, 'Sleep stage N2'],\n",
       "   [14760.0, 30.0, 'Sleep stage N2'],\n",
       "   [14790.0, 30.0, 'Sleep stage N2'],\n",
       "   [14820.0, 30.0, 'Sleep stage N2'],\n",
       "   [14850.0, 30.0, 'Sleep stage N2'],\n",
       "   [14880.0, 30.0, 'Sleep stage N2'],\n",
       "   [14910.0, 30.0, 'Sleep stage N2'],\n",
       "   [14940.0, 30.0, 'Sleep stage N2'],\n",
       "   [14970.0, 30.0, 'Sleep stage N2'],\n",
       "   [15000.0, 30.0, 'Sleep stage N2'],\n",
       "   [15030.0, 30.0, 'Sleep stage N2'],\n",
       "   [15060.0, 30.0, 'Sleep stage N2'],\n",
       "   [15090.0, 30.0, 'Sleep stage N2'],\n",
       "   [15120.0, 30.0, 'Sleep stage N2'],\n",
       "   [15150.0, 30.0, 'Sleep stage N1'],\n",
       "   [15180.0, 30.0, 'Sleep stage N2'],\n",
       "   [15210.0, 30.0, 'Sleep stage N2'],\n",
       "   [15240.0, 30.0, 'Sleep stage N2'],\n",
       "   [15270.0, 30.0, 'Sleep stage N2'],\n",
       "   [15300.0, 30.0, 'Sleep stage N2'],\n",
       "   [15330.0, 30.0, 'Sleep stage N2'],\n",
       "   [15360.0, 30.0, 'Sleep stage N2'],\n",
       "   [15390.0, 30.0, 'Sleep stage N2'],\n",
       "   [15420.0, 30.0, 'Sleep stage N2'],\n",
       "   [15450.0, 30.0, 'Sleep stage N2'],\n",
       "   [15480.0, 30.0, 'Sleep stage N2'],\n",
       "   [15510.0, 30.0, 'Sleep stage N2'],\n",
       "   [15540.0, 30.0, 'Sleep stage R'],\n",
       "   [15570.0, 30.0, 'Sleep stage R'],\n",
       "   [15600.0, 30.0, 'Sleep stage R'],\n",
       "   [15630.0, 30.0, 'Sleep stage R'],\n",
       "   [15660.0, 30.0, 'Sleep stage R'],\n",
       "   [15690.0, 30.0, 'Sleep stage R'],\n",
       "   [15720.0, 30.0, 'Sleep stage R'],\n",
       "   [15750.0, 30.0, 'Sleep stage R'],\n",
       "   [15780.0, 30.0, 'Sleep stage R'],\n",
       "   [15810.0, 30.0, 'Sleep stage R'],\n",
       "   [15840.0, 30.0, 'Sleep stage R'],\n",
       "   [15870.0, 30.0, 'Sleep stage R'],\n",
       "   [15900.0, 30.0, 'Sleep stage R'],\n",
       "   [15930.0, 30.0, 'Sleep stage R'],\n",
       "   [15960.0, 30.0, 'Sleep stage R'],\n",
       "   [15990.0, 30.0, 'Sleep stage R'],\n",
       "   [16020.0, 30.0, 'Sleep stage R'],\n",
       "   [16050.0, 30.0, 'Sleep stage R'],\n",
       "   [16080.0, 30.0, 'Sleep stage R'],\n",
       "   [16110.0, 30.0, 'Sleep stage R'],\n",
       "   [16140.0, 30.0, 'Sleep stage R'],\n",
       "   [16170.0, 30.0, 'Sleep stage R'],\n",
       "   [16200.0, 30.0, 'Sleep stage R'],\n",
       "   [16230.0, 30.0, 'Sleep stage R'],\n",
       "   [16260.0, 30.0, 'Sleep stage R'],\n",
       "   [16290.0, 30.0, 'Sleep stage R'],\n",
       "   [16320.0, 30.0, 'Sleep stage R'],\n",
       "   [16350.0, 30.0, 'Sleep stage R'],\n",
       "   [16380.0, 30.0, 'Sleep stage N1'],\n",
       "   [16410.0, 30.0, 'Sleep stage R'],\n",
       "   [16440.0, 30.0, 'Sleep stage R'],\n",
       "   [16470.0, 30.0, 'Sleep stage R'],\n",
       "   [16500.0, 30.0, 'Sleep stage R'],\n",
       "   [16530.0, 30.0, 'Sleep stage R'],\n",
       "   [16560.0, 30.0, 'Sleep stage R'],\n",
       "   [16590.0, 30.0, 'Sleep stage R'],\n",
       "   [16620.0, 30.0, 'Sleep stage R'],\n",
       "   [16650.0, 30.0, 'Sleep stage R'],\n",
       "   [16680.0, 30.0, 'Sleep stage R'],\n",
       "   [16710.0, 30.0, 'Sleep stage R'],\n",
       "   [16740.0, 30.0, 'Sleep stage R'],\n",
       "   [16770.0, 30.0, 'Sleep stage R'],\n",
       "   [16800.0, 30.0, 'Sleep stage R'],\n",
       "   [16830.0, 30.0, 'Sleep stage R'],\n",
       "   [16860.0, 30.0, 'Sleep stage R'],\n",
       "   [16890.0, 30.0, 'Sleep stage R'],\n",
       "   [16920.0, 30.0, 'Sleep stage R'],\n",
       "   [16950.0, 30.0, 'Sleep stage R'],\n",
       "   [16980.0, 30.0, 'Sleep stage R'],\n",
       "   [17010.0, 30.0, 'Sleep stage R'],\n",
       "   [17040.0, 30.0, 'Sleep stage R'],\n",
       "   [17070.0, 30.0, 'Sleep stage R'],\n",
       "   [17100.0, 30.0, 'Sleep stage R'],\n",
       "   [17130.0, 30.0, 'Sleep stage R'],\n",
       "   [17160.0, 30.0, 'Sleep stage R'],\n",
       "   [17190.0, 30.0, 'Sleep stage R'],\n",
       "   [17220.0, 30.0, 'Sleep stage R'],\n",
       "   [17250.0, 30.0, 'Sleep stage W'],\n",
       "   [17280.0, 30.0, 'Sleep stage W'],\n",
       "   [17310.0, 30.0, 'Sleep stage W'],\n",
       "   [17340.0, 30.0, 'Sleep stage W'],\n",
       "   [17370.0, 30.0, 'Sleep stage W'],\n",
       "   [17400.0, 30.0, 'Sleep stage N1'],\n",
       "   [17430.0, 30.0, 'Sleep stage N1'],\n",
       "   [17460.0, 30.0, 'Sleep stage N1'],\n",
       "   [17490.0, 30.0, 'Sleep stage N1'],\n",
       "   [17520.0, 30.0, 'Sleep stage N1'],\n",
       "   [17550.0, 30.0, 'Sleep stage N1'],\n",
       "   [17580.0, 30.0, 'Sleep stage N1'],\n",
       "   [17610.0, 30.0, 'Sleep stage N1'],\n",
       "   [17640.0, 30.0, 'Sleep stage N1'],\n",
       "   [17670.0, 30.0, 'Sleep stage N1'],\n",
       "   [17700.0, 30.0, 'Sleep stage N1'],\n",
       "   [17730.0, 30.0, 'Sleep stage N1'],\n",
       "   [17760.0, 30.0, 'Sleep stage N2'],\n",
       "   [17790.0, 30.0, 'Sleep stage N2'],\n",
       "   [17820.0, 30.0, 'Sleep stage N2'],\n",
       "   [17850.0, 30.0, 'Sleep stage N2'],\n",
       "   [17880.0, 30.0, 'Sleep stage N2'],\n",
       "   [17910.0, 30.0, 'Sleep stage N2'],\n",
       "   [17940.0, 30.0, 'Sleep stage N2'],\n",
       "   [17970.0, 30.0, 'Sleep stage N2'],\n",
       "   [18000.0, 30.0, 'Sleep stage N2'],\n",
       "   [18030.0, 30.0, 'Sleep stage N2'],\n",
       "   [18060.0, 30.0, 'Sleep stage N2'],\n",
       "   [18090.0, 30.0, 'Sleep stage N2'],\n",
       "   [18120.0, 30.0, 'Sleep stage N2'],\n",
       "   [18150.0, 30.0, 'Sleep stage N2'],\n",
       "   [18180.0, 30.0, 'Sleep stage N2'],\n",
       "   [18210.0, 30.0, 'Sleep stage N2'],\n",
       "   [18240.0, 30.0, 'Sleep stage N2'],\n",
       "   [18270.0, 30.0, 'Sleep stage N2'],\n",
       "   [18300.0, 30.0, 'Sleep stage N2'],\n",
       "   [18330.0, 30.0, 'Sleep stage N2'],\n",
       "   [18360.0, 30.0, 'Sleep stage N2'],\n",
       "   [18390.0, 30.0, 'Sleep stage N2'],\n",
       "   [18420.0, 30.0, 'Sleep stage N2'],\n",
       "   [18450.0, 30.0, 'Sleep stage N2'],\n",
       "   [18480.0, 30.0, 'Sleep stage N2'],\n",
       "   [18510.0, 30.0, 'Sleep stage N2'],\n",
       "   [18540.0, 30.0, 'Sleep stage N2'],\n",
       "   [18570.0, 30.0, 'Sleep stage N2'],\n",
       "   [18600.0, 30.0, 'Sleep stage N2'],\n",
       "   [18630.0, 30.0, 'Sleep stage N2'],\n",
       "   [18660.0, 30.0, 'Sleep stage N2'],\n",
       "   [18690.0, 30.0, 'Sleep stage N2'],\n",
       "   [18720.0, 30.0, 'Sleep stage N2'],\n",
       "   [18750.0, 30.0, 'Sleep stage N2'],\n",
       "   [18780.0, 30.0, 'Sleep stage N2'],\n",
       "   [18810.0, 30.0, 'Sleep stage N2'],\n",
       "   [18840.0, 30.0, 'Sleep stage N2'],\n",
       "   [18870.0, 30.0, 'Sleep stage N2'],\n",
       "   [18900.0, 30.0, 'Sleep stage N2'],\n",
       "   [18930.0, 30.0, 'Sleep stage N2'],\n",
       "   [18960.0, 30.0, 'Sleep stage N2'],\n",
       "   [18990.0, 30.0, 'Sleep stage N2'],\n",
       "   [19020.0, 30.0, 'Sleep stage N2'],\n",
       "   [19050.0, 30.0, 'Sleep stage N2'],\n",
       "   [19080.0, 30.0, 'Sleep stage N2'],\n",
       "   [19110.0, 30.0, 'Sleep stage N2'],\n",
       "   [19140.0, 30.0, 'Sleep stage N2'],\n",
       "   [19170.0, 30.0, 'Sleep stage N2'],\n",
       "   [19200.0, 30.0, 'Sleep stage N2'],\n",
       "   [19230.0, 30.0, 'Sleep stage N2'],\n",
       "   [19260.0, 30.0, 'Sleep stage N2'],\n",
       "   [19290.0, 30.0, 'Sleep stage N2'],\n",
       "   [19320.0, 30.0, 'Sleep stage N3'],\n",
       "   [19350.0, 30.0, 'Sleep stage N3'],\n",
       "   [19380.0, 30.0, 'Sleep stage N3'],\n",
       "   [19410.0, 30.0, 'Sleep stage N3'],\n",
       "   [19440.0, 30.0, 'Sleep stage N2'],\n",
       "   [19470.0, 30.0, 'Sleep stage N3'],\n",
       "   [19500.0, 30.0, 'Sleep stage N2'],\n",
       "   [19530.0, 30.0, 'Sleep stage N2'],\n",
       "   [19560.0, 30.0, 'Sleep stage W'],\n",
       "   [19590.0, 30.0, 'Sleep stage W'],\n",
       "   [19620.0, 30.0, 'Sleep stage W'],\n",
       "   [19650.0, 30.0, 'Sleep stage N1'],\n",
       "   [19680.0, 30.0, 'Sleep stage N2'],\n",
       "   [19710.0, 30.0, 'Sleep stage N2'],\n",
       "   [19740.0, 30.0, 'Sleep stage N2'],\n",
       "   [19770.0, 30.0, 'Sleep stage N2'],\n",
       "   [19800.0, 30.0, 'Sleep stage N2'],\n",
       "   [19830.0, 30.0, 'Sleep stage N2'],\n",
       "   [19860.0, 30.0, 'Sleep stage N2'],\n",
       "   [19890.0, 30.0, 'Sleep stage N2'],\n",
       "   [19920.0, 30.0, 'Sleep stage N2'],\n",
       "   [19950.0, 30.0, 'Sleep stage N2'],\n",
       "   [19980.0, 30.0, 'Sleep stage N2'],\n",
       "   [20010.0, 30.0, 'Sleep stage N2'],\n",
       "   [20040.0, 30.0, 'Sleep stage N2'],\n",
       "   [20070.0, 30.0, 'Sleep stage N2'],\n",
       "   [20100.0, 30.0, 'Sleep stage N2'],\n",
       "   [20130.0, 30.0, 'Sleep stage N2'],\n",
       "   [20160.0, 30.0, 'Sleep stage N2'],\n",
       "   [20190.0, 30.0, 'Sleep stage N2'],\n",
       "   [20220.0, 30.0, 'Sleep stage N2'],\n",
       "   [20250.0, 30.0, 'Sleep stage N2'],\n",
       "   [20280.0, 30.0, 'Sleep stage N2'],\n",
       "   [20310.0, 30.0, 'Sleep stage N2'],\n",
       "   [20340.0, 30.0, 'Sleep stage N2'],\n",
       "   [20370.0, 30.0, 'Sleep stage N2'],\n",
       "   [20400.0, 30.0, 'Sleep stage N2'],\n",
       "   [20430.0, 30.0, 'Sleep stage N2'],\n",
       "   [20460.0, 30.0, 'Sleep stage N2'],\n",
       "   [20490.0, 30.0, 'Sleep stage N2'],\n",
       "   [20520.0, 30.0, 'Sleep stage N2'],\n",
       "   [20550.0, 30.0, 'Sleep stage N2'],\n",
       "   [20580.0, 30.0, 'Sleep stage N2'],\n",
       "   [20610.0, 30.0, 'Sleep stage N2'],\n",
       "   [20640.0, 30.0, 'Sleep stage N2'],\n",
       "   [20670.0, 30.0, 'Sleep stage N2'],\n",
       "   [20700.0, 30.0, 'Sleep stage R'],\n",
       "   [20730.0, 30.0, 'Sleep stage N1'],\n",
       "   [20760.0, 30.0, 'Sleep stage N1'],\n",
       "   [20790.0, 30.0, 'Sleep stage N1'],\n",
       "   [20820.0, 30.0, 'Sleep stage N1'],\n",
       "   [20850.0, 30.0, 'Sleep stage N1'],\n",
       "   [20880.0, 30.0, 'Sleep stage R'],\n",
       "   [20910.0, 30.0, 'Sleep stage R'],\n",
       "   [20940.0, 30.0, 'Sleep stage R'],\n",
       "   [20970.0, 30.0, 'Sleep stage R'],\n",
       "   [21000.0, 30.0, 'Sleep stage R'],\n",
       "   [21030.0, 30.0, 'Sleep stage R'],\n",
       "   [21060.0, 30.0, 'Sleep stage R'],\n",
       "   [21090.0, 30.0, 'Sleep stage R'],\n",
       "   [21120.0, 30.0, 'Sleep stage R'],\n",
       "   [21150.0, 30.0, 'Sleep stage R'],\n",
       "   [21180.0, 30.0, 'Sleep stage R'],\n",
       "   [21210.0, 30.0, 'Sleep stage R'],\n",
       "   [21240.0, 30.0, 'Sleep stage R'],\n",
       "   [21270.0, 30.0, 'Sleep stage R'],\n",
       "   [21300.0, 30.0, 'Sleep stage R'],\n",
       "   [21330.0, 30.0, 'Sleep stage R'],\n",
       "   [21360.0, 30.0, 'Sleep stage R'],\n",
       "   [21390.0, 30.0, 'Sleep stage R'],\n",
       "   [21420.0, 30.0, 'Sleep stage R'],\n",
       "   [21450.0, 30.0, 'Sleep stage R'],\n",
       "   [21480.0, 30.0, 'Sleep stage R'],\n",
       "   [21510.0, 30.0, 'Sleep stage R'],\n",
       "   [21540.0, 30.0, 'Sleep stage R'],\n",
       "   [21570.0, 30.0, 'Sleep stage R'],\n",
       "   [21600.0, 30.0, 'Sleep stage R'],\n",
       "   [21630.0, 30.0, 'Sleep stage R'],\n",
       "   [21660.0, 30.0, 'Sleep stage R'],\n",
       "   [21690.0, 30.0, 'Sleep stage R'],\n",
       "   [21720.0, 30.0, 'Sleep stage R'],\n",
       "   [21750.0, 30.0, 'Sleep stage R'],\n",
       "   [21780.0, 30.0, 'Sleep stage R'],\n",
       "   [21810.0, 30.0, 'Sleep stage R'],\n",
       "   [21840.0, 30.0, 'Sleep stage R'],\n",
       "   [21870.0, 30.0, 'Sleep stage R'],\n",
       "   [21900.0, 30.0, 'Sleep stage R'],\n",
       "   [21930.0, 30.0, 'Sleep stage R'],\n",
       "   [21960.0, 30.0, 'Sleep stage R'],\n",
       "   [21990.0, 30.0, 'Sleep stage R'],\n",
       "   [22020.0, 30.0, 'Sleep stage R'],\n",
       "   [22050.0, 30.0, 'Sleep stage R'],\n",
       "   [22080.0, 30.0, 'Sleep stage R'],\n",
       "   [22110.0, 30.0, 'Sleep stage R'],\n",
       "   [22140.0, 30.0, 'Sleep stage R'],\n",
       "   [22170.0, 30.0, 'Sleep stage R'],\n",
       "   [22200.0, 30.0, 'Sleep stage R'],\n",
       "   [22230.0, 30.0, 'Sleep stage R'],\n",
       "   [22260.0, 30.0, 'Sleep stage R'],\n",
       "   [22290.0, 30.0, 'Sleep stage R'],\n",
       "   [22320.0, 30.0, 'Sleep stage R'],\n",
       "   [22350.0, 30.0, 'Sleep stage R'],\n",
       "   [22380.0, 30.0, 'Sleep stage R'],\n",
       "   [22410.0, 30.0, 'Sleep stage R'],\n",
       "   [22440.0, 30.0, 'Sleep stage R'],\n",
       "   [22470.0, 30.0, 'Sleep stage R'],\n",
       "   [22500.0, 30.0, 'Sleep stage R'],\n",
       "   [22530.0, 30.0, 'Sleep stage R'],\n",
       "   [22560.0, 30.0, 'Sleep stage R'],\n",
       "   [22590.0, 30.0, 'Sleep stage R'],\n",
       "   [22620.0, 30.0, 'Sleep stage N1'],\n",
       "   [22650.0, 30.0, 'Sleep stage W'],\n",
       "   [22680.0, 30.0, 'Sleep stage N1'],\n",
       "   [22710.0, 30.0, 'Sleep stage N1'],\n",
       "   [22740.0, 30.0, 'Sleep stage N1'],\n",
       "   [22770.0, 30.0, 'Sleep stage N1'],\n",
       "   [22800.0, 30.0, 'Sleep stage N1'],\n",
       "   [22830.0, 30.0, 'Sleep stage N1'],\n",
       "   [22860.0, 30.0, 'Sleep stage N1'],\n",
       "   [22890.0, 30.0, 'Sleep stage N2'],\n",
       "   [22920.0, 30.0, 'Sleep stage N2'],\n",
       "   [22950.0, 30.0, 'Sleep stage N2'],\n",
       "   [22980.0, 30.0, 'Sleep stage N2'],\n",
       "   [23010.0, 30.0, 'Sleep stage N2'],\n",
       "   [23040.0, 30.0, 'Sleep stage N2'],\n",
       "   [23070.0, 30.0, 'Sleep stage N2'],\n",
       "   [23100.0, 30.0, 'Sleep stage N2'],\n",
       "   [23130.0, 30.0, 'Sleep stage N2'],\n",
       "   [23160.0, 30.0, 'Sleep stage N1'],\n",
       "   [23190.0, 30.0, 'Sleep stage N2'],\n",
       "   [23220.0, 30.0, 'Sleep stage N2'],\n",
       "   [23250.0, 30.0, 'Sleep stage N1'],\n",
       "   [23280.0, 30.0, 'Sleep stage W'],\n",
       "   [23310.0, 30.0, 'Sleep stage N1'],\n",
       "   [23340.0, 30.0, 'Sleep stage N1'],\n",
       "   [23370.0, 30.0, 'Sleep stage W'],\n",
       "   [23400.0, 30.0, 'Sleep stage W'],\n",
       "   [23430.0, 30.0, 'Sleep stage W'],\n",
       "   [23460.0, 30.0, 'Sleep stage W'],\n",
       "   [23490.0, 30.0, 'Sleep stage W'],\n",
       "   [23520.0, 30.0, 'Sleep stage W'],\n",
       "   [23550.0, 30.0, 'Sleep stage W'],\n",
       "   [23580.0, 30.0, 'Sleep stage W'],\n",
       "   [23610.0, 30.0, 'Sleep stage W'],\n",
       "   [23640.0, 30.0, 'Sleep stage W'],\n",
       "   [23670.0, 30.0, 'Sleep stage W'],\n",
       "   [23700.0, 30.0, 'Sleep stage W'],\n",
       "   [23730.0, 30.0, 'Sleep stage W'],\n",
       "   [23760.0, 30.0, 'Sleep stage W'],\n",
       "   [23790.0, 30.0, 'Sleep stage W'],\n",
       "   [23820.0, 30.0, 'Sleep stage W'],\n",
       "   [23850.0, 30.0, 'Sleep stage W'],\n",
       "   [23880.0, 30.0, 'Sleep stage W'],\n",
       "   [23910.0, 30.0, 'Sleep stage N1'],\n",
       "   [23940.0, 30.0, 'Sleep stage N1'],\n",
       "   [23970.0, 30.0, 'Sleep stage N1'],\n",
       "   [24000.0, 30.0, 'Sleep stage N1'],\n",
       "   [24030.0, 30.0, 'Sleep stage N1'],\n",
       "   [24060.0, 30.0, 'Sleep stage N2'],\n",
       "   [24090.0, 30.0, 'Sleep stage N2'],\n",
       "   [24120.0, 30.0, 'Sleep stage N2'],\n",
       "   [24150.0, 30.0, 'Sleep stage N2'],\n",
       "   [24180.0, 30.0, 'Sleep stage N2'],\n",
       "   [24210.0, 30.0, 'Sleep stage N2'],\n",
       "   [24240.0, 30.0, 'Sleep stage N2'],\n",
       "   [24270.0, 30.0, 'Sleep stage N2'],\n",
       "   [24300.0, 30.0, 'Sleep stage N2'],\n",
       "   [24330.0, 30.0, 'Sleep stage N2'],\n",
       "   [24360.0, 30.0, 'Sleep stage N2'],\n",
       "   [24390.0, 30.0, 'Sleep stage N2'],\n",
       "   [24420.0, 30.0, 'Sleep stage N2'],\n",
       "   [24450.0, 30.0, 'Sleep stage N2'],\n",
       "   [24480.0, 30.0, 'Sleep stage N2'],\n",
       "   [24510.0, 30.0, 'Sleep stage N2'],\n",
       "   [24540.0, 30.0, 'Sleep stage N2'],\n",
       "   [24570.0, 30.0, 'Sleep stage N2'],\n",
       "   [24600.0, 30.0, 'Sleep stage N2'],\n",
       "   [24630.0, 30.0, 'Sleep stage N2'],\n",
       "   [24660.0, 30.0, 'Sleep stage N2'],\n",
       "   [24690.0, 30.0, 'Sleep stage N2'],\n",
       "   [24720.0, 30.0, 'Sleep stage N2'],\n",
       "   [24750.0, 30.0, 'Sleep stage N2'],\n",
       "   [24780.0, 30.0, 'Sleep stage N2'],\n",
       "   [24810.0, 30.0, 'Sleep stage N2'],\n",
       "   [24840.0, 30.0, 'Sleep stage N2'],\n",
       "   [24870.0, 30.0, 'Sleep stage N2'],\n",
       "   [24900.0, 30.0, 'Sleep stage N2'],\n",
       "   [24930.0, 30.0, 'Sleep stage N2'],\n",
       "   [24960.0, 30.0, 'Sleep stage N2'],\n",
       "   [24990.0, 30.0, 'Sleep stage N2'],\n",
       "   [25020.0, 30.0, 'Sleep stage N2'],\n",
       "   [25050.0, 30.0, 'Sleep stage N2'],\n",
       "   [25080.0, 30.0, 'Sleep stage N2'],\n",
       "   [25110.0, 30.0, 'Sleep stage N2'],\n",
       "   [25140.0, 30.0, 'Sleep stage N2'],\n",
       "   [25170.0, 30.0, 'Sleep stage N2'],\n",
       "   [25200.0, 30.0, 'Sleep stage N2'],\n",
       "   [25230.0, 30.0, 'Sleep stage N2'],\n",
       "   [25260.0, 30.0, 'Sleep stage N2'],\n",
       "   [25290.0, 30.0, 'Sleep stage N2'],\n",
       "   [25320.0, 30.0, 'Sleep stage W'],\n",
       "   [25350.0, 30.0, 'Sleep stage W'],\n",
       "   [25380.0, 30.0, 'Sleep stage W'],\n",
       "   [25410.0, 30.0, 'Sleep stage W'],\n",
       "   [25440.0, 30.0, 'Sleep stage W'],\n",
       "   [25470.0, 30.0, 'Sleep stage W'],\n",
       "   [25500.0, 30.0, 'Sleep stage W'],\n",
       "   [25530.0, 30.0, 'Sleep stage W'],\n",
       "   [25560.0, 30.0, 'Sleep stage W'],\n",
       "   [25590.0, 30.0, 'Sleep stage W'],\n",
       "   [25618.74, 0.0, 'Lights on@@EEG Fpz-Cz']]})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlevel.read_edf(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technician': '',\n",
       " 'recording_additional': '',\n",
       " 'patientname': 'Female 33yr',\n",
       " 'patient_additional': '',\n",
       " 'patientcode': '',\n",
       " 'equipment': '',\n",
       " 'admincode': '',\n",
       " 'sex': 'Female',\n",
       " 'startdate': datetime.datetime(1989, 4, 24, 16, 13),\n",
       " 'birthdate': '',\n",
       " 'gender': 'Female',\n",
       " 'annotations': [[0.0, 30630.0, 'Sleep stage W'],\n",
       "  [30630.0, 120.0, 'Sleep stage 1'],\n",
       "  [30750.0, 390.0, 'Sleep stage 2'],\n",
       "  [31140.0, 30.0, 'Sleep stage 3'],\n",
       "  [31170.0, 30.0, 'Sleep stage 2'],\n",
       "  [31200.0, 150.0, 'Sleep stage 3'],\n",
       "  [31350.0, 30.0, 'Sleep stage 4'],\n",
       "  [31380.0, 60.0, 'Sleep stage 3'],\n",
       "  [31440.0, 60.0, 'Sleep stage 4'],\n",
       "  [31500.0, 30.0, 'Sleep stage 3'],\n",
       "  [31530.0, 120.0, 'Sleep stage 4'],\n",
       "  [31650.0, 30.0, 'Sleep stage 3'],\n",
       "  [31680.0, 120.0, 'Sleep stage 4'],\n",
       "  [31800.0, 30.0, 'Sleep stage W'],\n",
       "  [31830.0, 60.0, 'Sleep stage 3'],\n",
       "  [31890.0, 60.0, 'Sleep stage 2'],\n",
       "  [31950.0, 120.0, 'Sleep stage 3'],\n",
       "  [32070.0, 30.0, 'Sleep stage 4'],\n",
       "  [32100.0, 30.0, 'Sleep stage 3'],\n",
       "  [32130.0, 120.0, 'Sleep stage 4'],\n",
       "  [32250.0, 210.0, 'Sleep stage 2'],\n",
       "  [32460.0, 30.0, 'Sleep stage 3'],\n",
       "  [32490.0, 60.0, 'Sleep stage 2'],\n",
       "  [32550.0, 120.0, 'Sleep stage 3'],\n",
       "  [32670.0, 30.0, 'Sleep stage 1'],\n",
       "  [32700.0, 150.0, 'Sleep stage 2'],\n",
       "  [32850.0, 60.0, 'Sleep stage 3'],\n",
       "  [32910.0, 30.0, 'Sleep stage 2'],\n",
       "  [32940.0, 30.0, 'Sleep stage 3'],\n",
       "  [32970.0, 30.0, 'Sleep stage 2'],\n",
       "  [33000.0, 120.0, 'Sleep stage 3'],\n",
       "  [33120.0, 150.0, 'Sleep stage 4'],\n",
       "  [33270.0, 30.0, 'Sleep stage 3'],\n",
       "  [33300.0, 30.0, 'Sleep stage 2'],\n",
       "  [33330.0, 60.0, 'Sleep stage 3'],\n",
       "  [33390.0, 30.0, 'Sleep stage 4'],\n",
       "  [33420.0, 90.0, 'Sleep stage 3'],\n",
       "  [33510.0, 1890.0, 'Sleep stage 4'],\n",
       "  [35400.0, 30.0, 'Sleep stage 1'],\n",
       "  [35430.0, 210.0, 'Sleep stage 3'],\n",
       "  [35640.0, 60.0, 'Sleep stage 2'],\n",
       "  [35700.0, 90.0, 'Sleep stage 3'],\n",
       "  [35790.0, 150.0, 'Sleep stage 2'],\n",
       "  [35940.0, 30.0, 'Sleep stage 3'],\n",
       "  [35970.0, 870.0, 'Sleep stage R'],\n",
       "  [36840.0, 180.0, 'Sleep stage 1'],\n",
       "  [37020.0, 240.0, 'Sleep stage 2'],\n",
       "  [37260.0, 30.0, 'Sleep stage 3'],\n",
       "  [37290.0, 120.0, 'Sleep stage 1'],\n",
       "  [37410.0, 90.0, 'Sleep stage 2'],\n",
       "  [37500.0, 30.0, 'Sleep stage 1'],\n",
       "  [37530.0, 930.0, 'Sleep stage 2'],\n",
       "  [38460.0, 30.0, 'Sleep stage 3'],\n",
       "  [38490.0, 30.0, 'Sleep stage 2'],\n",
       "  [38520.0, 60.0, 'Sleep stage 3'],\n",
       "  [38580.0, 30.0, 'Sleep stage 4'],\n",
       "  [38610.0, 30.0, 'Sleep stage 3'],\n",
       "  [38640.0, 30.0, 'Sleep stage 4'],\n",
       "  [38670.0, 30.0, 'Sleep stage 3'],\n",
       "  [38700.0, 30.0, 'Sleep stage 4'],\n",
       "  [38730.0, 30.0, 'Sleep stage 3'],\n",
       "  [38760.0, 150.0, 'Sleep stage 2'],\n",
       "  [38910.0, 60.0, 'Sleep stage 3'],\n",
       "  [38970.0, 90.0, 'Sleep stage 4'],\n",
       "  [39060.0, 60.0, 'Sleep stage 3'],\n",
       "  [39120.0, 30.0, 'Sleep stage 4'],\n",
       "  [39150.0, 30.0, 'Sleep stage 3'],\n",
       "  [39180.0, 60.0, 'Sleep stage 4'],\n",
       "  [39240.0, 60.0, 'Sleep stage 3'],\n",
       "  [39300.0, 180.0, 'Sleep stage 4'],\n",
       "  [39480.0, 60.0, 'Sleep stage 3'],\n",
       "  [39540.0, 30.0, 'Sleep stage 4'],\n",
       "  [39570.0, 30.0, 'Sleep stage 3'],\n",
       "  [39600.0, 270.0, 'Sleep stage 4'],\n",
       "  [39870.0, 30.0, 'Sleep stage 1'],\n",
       "  [39900.0, 60.0, 'Sleep stage 2'],\n",
       "  [39960.0, 30.0, 'Sleep stage 1'],\n",
       "  [39990.0, 210.0, 'Sleep stage 2'],\n",
       "  [40200.0, 30.0, 'Sleep stage 1'],\n",
       "  [40230.0, 60.0, 'Sleep stage 2'],\n",
       "  [40290.0, 30.0, 'Sleep stage 1'],\n",
       "  [40320.0, 180.0, 'Sleep stage 2'],\n",
       "  [40500.0, 870.0, 'Sleep stage R'],\n",
       "  [41370.0, 30.0, 'Sleep stage 2'],\n",
       "  [41400.0, 60.0, 'Sleep stage 1'],\n",
       "  [41460.0, 30.0, 'Sleep stage W'],\n",
       "  [41490.0, 120.0, 'Sleep stage 1'],\n",
       "  [41610.0, 870.0, 'Sleep stage 2'],\n",
       "  [42480.0, 30.0, 'Sleep stage 1'],\n",
       "  [42510.0, 30.0, 'Sleep stage 2'],\n",
       "  [42540.0, 30.0, 'Sleep stage 1'],\n",
       "  [42570.0, 300.0, 'Sleep stage 2'],\n",
       "  [42870.0, 30.0, 'Sleep stage 3'],\n",
       "  [42900.0, 390.0, 'Sleep stage 2'],\n",
       "  [43290.0, 30.0, 'Sleep stage 3'],\n",
       "  [43320.0, 30.0, 'Sleep stage 2'],\n",
       "  [43350.0, 30.0, 'Sleep stage 3'],\n",
       "  [43380.0, 30.0, 'Sleep stage 2'],\n",
       "  [43410.0, 180.0, 'Sleep stage 3'],\n",
       "  [43590.0, 90.0, 'Sleep stage 4'],\n",
       "  [43680.0, 30.0, 'Sleep stage 3'],\n",
       "  [43710.0, 210.0, 'Sleep stage 2'],\n",
       "  [43920.0, 60.0, 'Sleep stage 3'],\n",
       "  [43980.0, 30.0, 'Sleep stage 2'],\n",
       "  [44010.0, 30.0, 'Sleep stage 4'],\n",
       "  [44040.0, 180.0, 'Sleep stage 3'],\n",
       "  [44220.0, 60.0, 'Sleep stage 4'],\n",
       "  [44280.0, 60.0, 'Sleep stage 3'],\n",
       "  [44340.0, 60.0, 'Sleep stage 4'],\n",
       "  [44400.0, 120.0, 'Sleep stage 3'],\n",
       "  [44520.0, 120.0, 'Sleep stage 2'],\n",
       "  [44640.0, 30.0, 'Sleep stage 3'],\n",
       "  [44670.0, 30.0, 'Sleep stage 4'],\n",
       "  [44700.0, 30.0, 'Sleep stage 2'],\n",
       "  [44730.0, 240.0, 'Sleep stage R'],\n",
       "  [44970.0, 30.0, 'Sleep stage 1'],\n",
       "  [45000.0, 510.0, 'Sleep stage R'],\n",
       "  [45510.0, 30.0, 'Sleep stage W'],\n",
       "  [45540.0, 120.0, 'Sleep stage 1'],\n",
       "  [45660.0, 480.0, 'Sleep stage W'],\n",
       "  [46140.0, 90.0, 'Sleep stage 1'],\n",
       "  [46230.0, 30.0, 'Sleep stage W'],\n",
       "  [46260.0, 120.0, 'Sleep stage 1'],\n",
       "  [46380.0, 690.0, 'Sleep stage 2'],\n",
       "  [47070.0, 60.0, 'Sleep stage W'],\n",
       "  [47130.0, 30.0, 'Sleep stage 1'],\n",
       "  [47160.0, 990.0, 'Sleep stage 2'],\n",
       "  [48150.0, 30.0, 'Sleep stage 3'],\n",
       "  [48180.0, 30.0, 'Sleep stage 2'],\n",
       "  [48210.0, 90.0, 'Sleep stage 3'],\n",
       "  [48300.0, 120.0, 'Sleep stage 2'],\n",
       "  [48420.0, 60.0, 'Sleep stage 3'],\n",
       "  [48480.0, 60.0, 'Sleep stage 2'],\n",
       "  [48540.0, 30.0, 'Sleep stage 3'],\n",
       "  [48570.0, 30.0, 'Sleep stage 2'],\n",
       "  [48600.0, 30.0, 'Sleep stage 3'],\n",
       "  [48630.0, 30.0, 'Sleep stage 2'],\n",
       "  [48660.0, 120.0, 'Sleep stage 3'],\n",
       "  [48780.0, 210.0, 'Sleep stage 2'],\n",
       "  [48990.0, 30.0, 'Sleep stage 3'],\n",
       "  [49020.0, 120.0, 'Sleep stage 2'],\n",
       "  [49140.0, 60.0, 'Sleep stage 1'],\n",
       "  [49200.0, 990.0, 'Sleep stage R'],\n",
       "  [50190.0, 30.0, 'Sleep stage W'],\n",
       "  [50220.0, 150.0, 'Sleep stage 1'],\n",
       "  [50370.0, 270.0, 'Sleep stage R'],\n",
       "  [50640.0, 510.0, 'Sleep stage W'],\n",
       "  [51150.0, 90.0, 'Sleep stage 1'],\n",
       "  [51240.0, 300.0, 'Sleep stage W'],\n",
       "  [51540.0, 30.0, 'Sleep stage 1'],\n",
       "  [51570.0, 540.0, 'Sleep stage W'],\n",
       "  [52110.0, 150.0, 'Sleep stage 1'],\n",
       "  [52260.0, 27240.0, 'Sleep stage W'],\n",
       "  [79500.0, 6900.0, 'Sleep stage ?']]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlevel.read_edf(labels[0])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>sleep_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30630.0</td>\n",
       "      <td>Sleep stage W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30630.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Sleep stage 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30750.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>Sleep stage 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31140.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Sleep stage 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31170.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Sleep stage 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>51540.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Sleep stage 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>51570.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>Sleep stage W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>52110.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Sleep stage 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>52260.0</td>\n",
       "      <td>27240.0</td>\n",
       "      <td>Sleep stage W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>79500.0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>Sleep stage ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  duration    sleep_stage\n",
       "0        0.0   30630.0  Sleep stage W\n",
       "1    30630.0     120.0  Sleep stage 1\n",
       "2    30750.0     390.0  Sleep stage 2\n",
       "3    31140.0      30.0  Sleep stage 3\n",
       "4    31170.0      30.0  Sleep stage 2\n",
       "..       ...       ...            ...\n",
       "149  51540.0      30.0  Sleep stage 1\n",
       "150  51570.0     540.0  Sleep stage W\n",
       "151  52110.0     150.0  Sleep stage 1\n",
       "152  52260.0   27240.0  Sleep stage W\n",
       "153  79500.0    6900.0  Sleep stage ?\n",
       "\n",
       "[154 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(highlevel.read_edf(labels[0])[2]['annotations'])\n",
    "df1.columns=['time', 'duration', 'sleep_stage']\n",
    "df1\n",
    "# 0  30630  Sleep stage W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "psg_fnames = glob(os.path.join('./data/data2013/', \"*PSG.edf\"))\n",
    "\n",
    "f = open(psg_fnames[0], 'r', encoding='ISO-8859-1')\n",
    "\n",
    "# print(f.tell())  # check file position\n",
    "print(f.tell() == 0)  # check file position\n",
    "print(f.read(8) == '0       ')\n",
    "# print(f.read(8) == '0       ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[[ 1.1765324e-03]\n",
      "  [ 1.0187301e-03]\n",
      "  [ 2.2971917e-04]\n",
      "  ...\n",
      "  [ 2.9108670e-04]\n",
      "  [ 1.4395360e-03]\n",
      "  [ 5.4532359e-04]]\n",
      "\n",
      " [[ 1.2729671e-03]\n",
      "  [-7.9599512e-04]\n",
      "  [ 1.4044689e-03]\n",
      "  ...\n",
      "  [ 5.3655676e-04]\n",
      "  [ 2.2285471e-03]\n",
      "  [ 5.8039074e-04]]\n",
      "\n",
      " [[ 1.9304762e-03]\n",
      "  [ 6.8559218e-04]\n",
      "  [ 2.5441514e-03]\n",
      "  ...\n",
      "  [ 1.2451770e-04]\n",
      "  [-9.9763123e-04]\n",
      "  [ 5.4532359e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-6.9502806e-03]\n",
      "  [-9.5364833e-03]\n",
      "  [-6.1963368e-03]\n",
      "  ...\n",
      "  [-1.9985349e-04]\n",
      "  [ 2.7019535e-03]\n",
      "  [ 2.0341881e-04]]\n",
      "\n",
      " [[ 4.1660075e-03]\n",
      "  [ 5.1902322e-04]\n",
      "  [ 3.1490598e-03]\n",
      "  ...\n",
      "  [-3.8395604e-04]\n",
      "  [ 1.0187301e-03]\n",
      "  [-7.7118435e-05]]\n",
      "\n",
      " [[ 1.4307692e-03]\n",
      "  [ 1.9465202e-04]\n",
      "  [ 1.3431014e-03]\n",
      "  ...\n",
      "  [ 2.8231990e-04]\n",
      "  [-1.0326984e-03]\n",
      "  [ 7.8202685e-04]]]\n",
      "y\n",
      "[0 0 0 ... 0 0 0]\n",
      "fs\n",
      "100.0\n",
      "ch_label\n",
      "EEG Fpz-Cz\n",
      "header_raw\n",
      "{'local_subject_id': 'X F X Female_54yr', 'local_recording_id': 'Startdate 02-APR-1990 X X X', 'date_time': '2090-04-02 12:15:00', 'EDF+': False, 'contiguous': True, 'n_records': 2870, 'record_length': 30.0, 'n_channels': 7, 'label': ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker'], 'transducer_type': ['Ag-AgCl electrodes', 'Ag-AgCl electrodes', 'Ag-AgCl electrodes', 'Oral-nasal thermistors', 'Ag-AgCl electrodes', 'Rectal thermistor', 'Marker button'], 'units': ['uV', 'uV', 'uV', '', 'uV', '', ''], 'physical_min': array([ -179.,  -205.,  -902., -2048.,    -5.,     0., -2047.]), 'physical_max': array([ 180.,  206.,  902., 2047.,    5.,   30., 2048.]), 'digital_min': array([ -2048.,  -2048.,  -2048.,  -2048.,  -2500., -32768.,  -2047.]), 'digital_max': array([ 2047.,  2047.,  2047.,  2047.,  2500., 32767.,  2048.]), 'prefiltering': ['HP:0.5Hz LP:100Hz [enhanced cassette BW]', 'HP:0.5Hz LP:100Hz [enhanced cassette BW]', 'HP:0.5Hz LP:100Hz [enhanced cassette BW]', 'HP:0.03Hz LP:0.9Hz', 'HP:16Hz Rectification LP:0.7Hz', '', 'Hold during 2 seconds'], 'n_samples_per_record': [3000, 3000, 3000, 30, 30, 30, 30]}\n",
      "header_annotation\n",
      "{'local_subject_id': 'X F X Female_54yr', 'local_recording_id': 'Startdate 02-APR-1990 X X X', 'date_time': '2090-04-02 12:15:00', 'EDF+': True, 'contiguous': True, 'n_records': 1, 'record_length': 0.0, 'n_channels': 1, 'label': ['EDF Annotations'], 'transducer_type': [''], 'units': [''], 'physical_min': array([0.]), 'physical_max': array([1.]), 'digital_min': array([-32768.]), 'digital_max': array([32767.]), 'prefiltering': [''], 'n_samples_per_record': [2256]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load('./data/data2013/eeg_fpg_cz/SC4272F0.npz', allow_pickle=True)\n",
    "\n",
    "for i in data:\n",
    "    print(i)\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /mnt/d/home/GoodSleep/data/data2013/SC4001E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 7949999  =      0.000 ... 79499.990 secs...\n",
      "raw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>April 24, 1989  16:13:00 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            \n",
       "            <td>X</td>\n",
       "            \n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>Not available</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>7 EEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>100.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.50 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>100.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Filenames</th>\n",
       "                    <td>SC4001E0-PSG.edf</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>22:04:60 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawEDF | SC4001E0-PSG.edf, 7 x 7950000 (79500.0 s), ~424.6 MB, data loaded>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling_rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_ch_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG Fpz-Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949995</th>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949996</th>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949997</th>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949998</th>\n",
       "      <td>-0.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949999</th>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7950000 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EEG Fpz-Cz\n",
       "0          0.000502\n",
       "1         -0.000258\n",
       "2          0.000136\n",
       "3         -0.000239\n",
       "4         -0.000520\n",
       "...             ...\n",
       "7949995    0.001130\n",
       "7949996    0.000361\n",
       "7949997    0.000530\n",
       "7949998   -0.000464\n",
       "7949999    0.000661\n",
       "\n",
       "[7950000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from mne import Epochs, pick_types, find_events\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "\n",
    "psg_fnames = glob(os.path.join('./data/data2013/', \"*PSG.edf\"))\n",
    "np.asarray(psg_fnames)\n",
    "i = 0\n",
    "select_ch='EEG Fpz-Cz'\n",
    "raw = read_raw_edf(psg_fnames[i], preload=True, stim_channel=None)\n",
    "sampling_rate = raw.info['sfreq']\n",
    "\n",
    "raw_ch_df = raw.to_data_frame(scalings=100.0)[select_ch]\n",
    "raw_ch_df = raw_ch_df.to_frame()\n",
    "raw_ch_df.set_index(np.arange(len(raw_ch_df)))\n",
    "\n",
    "print('raw')\n",
    "display(raw)\n",
    "print('sampling_rate')\n",
    "display(sampling_rate)\n",
    "print('raw_ch_df')\n",
    "display(raw_ch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data2013\n",
      "eeg_fpz_cz\n",
      "d:\\sejin\\GoodSleep\\data\\data2013\\traindata/\n",
      "2023-12-06 16:33:06.775158\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from dataloader import SeqDataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "num_folds = 20\n",
    "data_dir = 'data/data2013/eeg_fpz_cz'\n",
    "classes = ['W', 'N1', 'N2', 'N3', 'REM']\n",
    "checkpoint_dir = 'checkpoints-seq2seq-sleep-EDF'\n",
    "output_dir = 'outputs_2013/outputs_eeg_fpz_cz'\n",
    "\n",
    "hparams = {\n",
    "    'epochs': 120,\n",
    "    'batch_size': 20,\n",
    "    'num_units': 128,\n",
    "    'embed_size': 10,\n",
    "    'input_depth': 3000,\n",
    "    'n_channels': 100,\n",
    "    'bidirectional': True,\n",
    "    'use_attention': True,\n",
    "    'lstm_layers': 2,\n",
    "    'attention_size': 64,\n",
    "    'beam_width': 4,\n",
    "    'use_beamsearch_decode': False,\n",
    "    'max_time_step': 10,\n",
    "    'output_max_length': 10 + 2,\n",
    "    'akara2017': True,\n",
    "    'test_step': 5\n",
    "}\n",
    "\n",
    "path, channel_ename = os.path.split(data_dir)\n",
    "traindata_dir = os.path.join(os.path.abspath(os.path.join(data_dir, os.pardir)),'traindata/')\n",
    "\n",
    "print(path)\n",
    "print(channel_ename)\n",
    "print(traindata_dir)\n",
    "\n",
    "print((str(datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== [Fold-0] ==========\n",
      "\n",
      "Load training set:\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4232E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4271F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4411E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4292G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4512E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4061E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4491G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4601E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4121E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4172E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4332F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4171E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4272F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4822G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4811G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4311E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4382F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4742E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4362F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4561F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4621E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4722E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4252E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4772G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4331F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4162E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4441E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4591G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4381F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4201E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4341F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4801G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4042E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4002E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4602E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4291G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4752E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4181E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4321E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4762E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4351F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4651E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4112E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4542F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4202E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4551F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4432E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4492G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4431E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4251E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4672G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4212E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4451F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4732E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4711E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4001E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4152E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4482F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4462F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4751E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4122E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4101E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4372F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4721E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4012E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4102E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4091E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4812G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4541F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4301E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4661E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4072E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4662E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4571F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4402E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4051E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4622E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4191E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4352F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4151E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4702E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4032E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4222E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4182E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4611E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4142E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4022E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4062E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4502E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4081E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4322E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4712E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4501E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4342F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4241E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4371F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4572F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4532E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4192E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4701E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4041E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4581G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4671G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4802G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4021E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4761E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4552F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4471F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4472F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4312E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4282G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4011E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4231E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4082E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4242E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4741E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4612E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4652E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4452F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4582G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4481F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4031E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4092E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4071E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4562F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4631E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4821G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4052E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4141E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4592G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4421E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4632E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4771G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4461F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4422E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4161E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4731E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4111E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4641E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4511E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4221E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4642E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4281G0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4211E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4531E0.npz ...\n",
      " \n",
      "Load Test set:\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4261F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4131E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4401E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4302E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4522E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4442E0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4262F0.npz ...\n",
      "Loading data/data2013/eeg_fpz_cz\\SC4412E0.npz ...\n",
      " \n",
      "Training set: n_subjects=145\n",
      "(1729, 3000)\n",
      "(1052, 3000)\n",
      "(1078, 3000)\n",
      "(1605, 3000)\n",
      "(954, 3000)\n",
      "(843, 3000)\n",
      "(1101, 3000)\n",
      "(1349, 3000)\n",
      "(1052, 3000)\n",
      "(1773, 3000)\n",
      "(1312, 3000)\n",
      "(1002, 3000)\n",
      "(1090, 3000)\n",
      "(1366, 3000)\n",
      "(1293, 3000)\n",
      "(1054, 3000)\n",
      "(1871, 3000)\n",
      "(1063, 3000)\n",
      "(824, 3000)\n",
      "(1237, 3000)\n",
      "(1445, 3000)\n",
      "(1130, 3000)\n",
      "(1020, 3000)\n",
      "(1324, 3000)\n",
      "(1888, 3000)\n",
      "(1003, 3000)\n",
      "(1195, 3000)\n",
      "(1840, 3000)\n",
      "(1776, 3000)\n",
      "(1022, 3000)\n",
      "(1501, 3000)\n",
      "(1241, 3000)\n",
      "(1200, 3000)\n",
      "(1127, 3000)\n",
      "(2043, 3000)\n",
      "(1131, 3000)\n",
      "(1049, 3000)\n",
      "(964, 3000)\n",
      "(1560, 3000)\n",
      "(2662, 3000)\n",
      "(976, 3000)\n",
      "(2644, 3000)\n",
      "(802, 3000)\n",
      "(1148, 3000)\n",
      "(1021, 3000)\n",
      "(1047, 3000)\n",
      "(962, 3000)\n",
      "(1040, 3000)\n",
      "(699, 3000)\n",
      "(972, 3000)\n",
      "(1021, 3000)\n",
      "(808, 3000)\n",
      "(1208, 3000)\n",
      "(2318, 3000)\n",
      "(1413, 3000)\n",
      "(841, 3000)\n",
      "(1762, 3000)\n",
      "(1910, 3000)\n",
      "(1022, 3000)\n",
      "(2044, 3000)\n",
      "(977, 3000)\n",
      "(1104, 3000)\n",
      "(1509, 3000)\n",
      "(1031, 3000)\n",
      "(1186, 3000)\n",
      "(1092, 3000)\n",
      "(1132, 3000)\n",
      "(1183, 3000)\n",
      "(1716, 3000)\n",
      "(929, 3000)\n",
      "(2026, 3000)\n",
      "(1273, 3000)\n",
      "(1994, 3000)\n",
      "(1236, 3000)\n",
      "(1072, 3000)\n",
      "(672, 3000)\n",
      "(1823, 3000)\n",
      "(1535, 3000)\n",
      "(963, 3000)\n",
      "(952, 3000)\n",
      "(1515, 3000)\n",
      "(911, 3000)\n",
      "(1108, 3000)\n",
      "(920, 3000)\n",
      "(1652, 3000)\n",
      "(952, 3000)\n",
      "(1009, 3000)\n",
      "(1016, 3000)\n",
      "(1103, 3000)\n",
      "(1134, 3000)\n",
      "(1021, 3000)\n",
      "(1241, 3000)\n",
      "(1326, 3000)\n",
      "(1582, 3000)\n",
      "(1673, 3000)\n",
      "(918, 3000)\n",
      "(1095, 3000)\n",
      "(1056, 3000)\n",
      "(1274, 3000)\n",
      "(1717, 3000)\n",
      "(1235, 3000)\n",
      "(1095, 3000)\n",
      "(1968, 3000)\n",
      "(1229, 3000)\n",
      "(1025, 3000)\n",
      "(1683, 3000)\n",
      "(1090, 3000)\n",
      "(1187, 3000)\n",
      "(2161, 3000)\n",
      "(1181, 3000)\n",
      "(1070, 3000)\n",
      "(1103, 3000)\n",
      "(904, 3000)\n",
      "(1054, 3000)\n",
      "(1775, 3000)\n",
      "(2210, 3000)\n",
      "(1062, 3000)\n",
      "(1929, 3000)\n",
      "(1166, 3000)\n",
      "(1175, 3000)\n",
      "(2027, 3000)\n",
      "(952, 3000)\n",
      "(1105, 3000)\n",
      "(976, 3000)\n",
      "(1148, 3000)\n",
      "(1063, 3000)\n",
      "(1704, 3000)\n",
      "(1246, 3000)\n",
      "(1004, 3000)\n",
      "(1231, 3000)\n",
      "(785, 3000)\n",
      "(1107, 3000)\n",
      "(1325, 3000)\n",
      "(983, 3000)\n",
      "(884, 3000)\n",
      "(1144, 3000)\n",
      "(2667, 3000)\n",
      "(928, 3000)\n",
      "(1271, 3000)\n",
      "(1087, 3000)\n",
      "(1099, 3000)\n",
      "(2049, 3000)\n",
      "(1127, 3000)\n",
      "(1578, 3000)\n",
      "(1096, 3000)\n",
      "Number of examples = 186943\n",
      "W: 63676\n",
      "N1: 20639\n",
      "N2: 65555\n",
      "N3: 12354\n",
      "REM: 24719\n",
      " \n",
      "Test set: n_subjects = 8\n",
      "(1597, 3000)\n",
      "(1028, 3000)\n",
      "(1064, 3000)\n",
      "(854, 3000)\n",
      "(997, 3000)\n",
      "(1092, 3000)\n",
      "(980, 3000)\n",
      "(924, 3000)\n",
      "Number of examples = 8536\n",
      "W: 2275\n",
      "N1: 883\n",
      "N2: 3577\n",
      "N3: 685\n",
      "REM: 1116\n",
      " \n",
      "1701847987.1614795\n",
      "[[[ 2.2580624e+00  2.2422836e+00  2.2738411e+00 ... -5.2426434e-01\n",
      "   -4.8218754e-01 -6.6101378e-01]\n",
      "  [-1.4005440e+00 -1.7986038e+00 -2.0691085e+00 ...  1.1692106e-01\n",
      "   -1.5798205e-01 -7.2212286e-02]\n",
      "  [-4.3044657e-02  1.5376006e-01  1.3755259e-01 ... -2.3058796e-01\n",
      "   -1.3102794e-01 -1.0787444e-01]\n",
      "  ...\n",
      "  [-1.3095157e+00  5.5856431e-01  8.4653908e-01 ... -4.6312028e-01\n",
      "   -2.9534361e-01 -3.8048398e-01]\n",
      "  [-2.2598518e-01 -2.8198025e-01 -3.1931031e-01 ... -3.2847152e+00\n",
      "   -3.0537357e+00 -2.6757691e+00]\n",
      "  [-1.6334993e+00 -1.5156195e+00 -1.0802240e+00 ...  2.6208645e-01\n",
      "    3.5524964e-01  4.2749864e-01]]\n",
      "\n",
      " [[-1.0029908e+00 -3.6183241e-01 -1.5345593e-01 ...  1.0567305e+00\n",
      "    1.0727595e+00 -1.5345593e-01]\n",
      "  [ 5.8709145e-01  3.6903533e-01  1.5901496e+00 ...  7.1792513e-01\n",
      "    5.0859123e-01  5.9581369e-01]\n",
      "  [ 1.1052359e+00  1.2903670e+00  1.1137422e-01 ...  9.1036099e-01\n",
      "    6.2779254e-01  8.8112986e-01]\n",
      "  ...\n",
      "  [-1.0624412e+00 -8.5702288e-01 -1.0713724e+00 ... -2.3183683e-01\n",
      "   -3.6580527e-01 -2.8542420e-01]\n",
      "  [-2.6938933e-01 -9.5560268e-02  2.6124674e-01 ... -6.8113565e-02\n",
      "   -5.0726074e-01 -9.7385448e-01]\n",
      "  [-1.0071282e+00 -1.1883501e+00 -8.9681935e-01 ... -1.1253164e+00\n",
      "   -1.1016787e+00 -7.0771837e-01]]\n",
      "\n",
      " [[-1.0216741e-01 -2.7657539e-01 -1.7747995e-01 ...  5.4789871e-01\n",
      "    7.0248765e-01  4.1709274e-01]\n",
      "  [ 2.0167091e-01  9.2708194e-01  1.9852504e+00 ... -2.7084452e-01\n",
      "   -3.1259224e-02 -5.1708496e-01]\n",
      "  [-5.2904332e-01 -7.8502107e-01 -9.2053866e-01 ...  3.0664879e-01\n",
      "    2.6147625e-01  8.0786064e-02]\n",
      "  ...\n",
      "  [ 2.9221758e-01  1.5434241e-01 -3.3352357e-01 ... -8.2138956e-01\n",
      "   -2.1471124e+00 -1.6698520e+00]\n",
      "  [-4.3505314e-01 -5.2087647e-01 -5.5132991e-01 ...  2.9859772e-01\n",
      "    2.9582927e-01  4.8962384e-01]\n",
      "  [ 1.8794081e-01  3.7763506e-01  1.3686927e-01 ... -2.1722937e+00\n",
      "   -1.1654547e+00 -1.3551490e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.1796947e+00  3.3019576e+00  3.3791761e+00 ...  3.0973473e-01\n",
      "    3.7408361e-01  1.5529744e-01]\n",
      "  [ 3.1176192e-01  2.1537299e-01  2.8766468e-01 ...  1.6717854e-01\n",
      "    5.7683140e-01  7.0936614e-01]\n",
      "  [ 1.0388167e+00  1.1894116e+00  1.1768620e+00 ... -5.2996874e-02\n",
      "   -1.7849270e-01 -2.7985505e-03]\n",
      "  ...\n",
      "  [ 6.3651168e-01  7.0144910e-01  7.9524761e-01 ... -9.5084715e-01\n",
      "   -9.0755552e-01 -1.0013540e+00]\n",
      "  [-8.5178208e-01 -8.7762046e-01 -8.1948417e-01 ... -1.4525232e+00\n",
      "   -1.3168721e+00 -1.3233316e+00]\n",
      "  [-1.9044300e+00 -1.5815685e+00 -1.4152459e+00 ...  5.7084209e-01\n",
      "    8.5456896e-01  1.1089448e+00]]\n",
      "\n",
      " [[ 1.9627818e-01  4.7432542e-01  3.2898253e-01 ...  5.5647576e-01\n",
      "    1.7100115e-01 -3.8509330e-01]\n",
      "  [-1.5413988e-01  3.3660263e-01 -1.9308770e-01 ...  1.5744266e-01\n",
      "    6.9492251e-01  7.4944949e-01]\n",
      "  [ 6.5594560e-01  7.0216662e-01  8.8705045e-01 ... -1.8348505e+00\n",
      "   -1.9324281e+00 -2.1378546e+00]\n",
      "  ...\n",
      "  [ 6.1950833e-01  8.4775889e-01  9.8669398e-01 ...  4.7064930e-01\n",
      "    1.7789316e-01 -5.0357360e-02]\n",
      "  [-3.9964372e-01 -5.4646716e-02  2.4192965e-01 ... -6.5385205e-01\n",
      "    1.7535128e-01  5.8790683e-03]\n",
      "  [-2.5730157e-01 -1.7617856e-01 -5.1225948e-01 ... -1.5686356e-01\n",
      "   -5.4702657e-01 -4.6976656e-01]]\n",
      "\n",
      " [[ 7.9187930e-01  1.3211051e+00  1.3139535e+00 ...  1.8398467e-01\n",
      "    4.8102338e-02  2.8410846e-01]\n",
      "  [ 4.4986191e-01  5.7519007e-01  9.6684057e-01 ... -1.7155683e-01\n",
      "    1.8353960e-01 -3.0732897e-01]\n",
      "  [-9.2783302e-02 -4.2464176e-01 -5.6711733e-02 ...  3.0400398e-01\n",
      "   -9.9997625e-02 -7.1140364e-02]\n",
      "  ...\n",
      "  [ 6.5647230e-02 -1.1008686e-01 -3.5611460e-01 ...  9.0214157e-01\n",
      "    8.5996532e-01  1.1270812e+00]\n",
      "  [ 9.5366597e-01  1.2299122e+00  8.8942271e-01 ...  2.6239915e+00\n",
      "    2.8295698e+00  2.7717512e+00]\n",
      "  [ 3.2661982e+00  2.5870144e+00  1.9584080e+00 ...  4.5553258e-01\n",
      "   -7.1918845e-02 -6.0659564e-01]]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]\n",
      " [0 0 1 ... 1 0 0]\n",
      " ...\n",
      " [1 1 1 ... 2 2 2]\n",
      " [4 4 4 ... 4 4 4]\n",
      " [2 2 2 ... 2 2 2]]\n",
      "[[[ 6.05638087e-01  6.13398671e-01  4.50426519e-01 ... -4.88603324e-01\n",
      "   -4.03236985e-01 -4.18758154e-01]\n",
      "  [-3.26964170e-01  6.22057207e-02 -1.73344478e-01 ... -3.37887502e+00\n",
      "   -3.18429017e+00 -2.84632707e+00]\n",
      "  [-2.16113734e+00 -1.81365740e+00 -1.99898016e+00 ...  3.32996458e-01\n",
      "    4.48823065e-01  5.95536888e-01]\n",
      "  ...\n",
      "  [-1.88190639e-01 -4.29090522e-02 -2.64654636e-01 ... -7.92256176e-01\n",
      "   -6.69913769e-01 -8.61073732e-01]\n",
      "  [-7.45605946e-01 -6.66029155e-01 -5.77610373e-01 ...  7.22145557e-01\n",
      "    9.16666806e-01  7.75196850e-01]\n",
      "  [ 7.29845345e-01  7.84199238e-01  6.66432500e-01 ... -8.10180366e-01\n",
      "   -3.75349551e-01 -5.47470093e-01]]\n",
      "\n",
      " [[ 1.30528316e-01 -2.66829193e-01 -4.58958089e-01 ...  2.17859641e-01\n",
      "    2.74625003e-01  2.70258427e-01]\n",
      "  [ 2.14122131e-01 -2.52821207e-01 -1.65019915e-01 ... -2.60803163e-01\n",
      "   -1.09146342e-01 -1.05155371e-01]\n",
      "  [-4.39110649e-04 -2.16643378e-01  1.46449106e-02 ... -8.70284200e-01\n",
      "   -5.98771870e-01 -6.18883908e-01]\n",
      "  ...\n",
      "  [-4.98481154e-01 -4.53019559e-01 -7.00532615e-01 ... -3.16634804e-01\n",
      "   -9.07635331e-01 -9.42994356e-01]\n",
      "  [-1.19175780e+00 -3.81409794e-01  1.47603434e-02 ...  7.47861192e-02\n",
      "   -9.32860598e-02  2.84876347e-01]\n",
      "  [ 4.67096828e-02  5.70448264e-02  1.39725953e-01 ... -2.32339159e-01\n",
      "   -2.56363116e-02  3.87769341e-01]]\n",
      "\n",
      " [[-6.28567338e-01 -4.48900998e-01 -6.47479534e-01 ...  4.87255007e-01\n",
      "    2.88676471e-01  8.93868268e-01]\n",
      "  [ 5.54404438e-01  9.49236333e-01  1.56816208e+00 ... -2.45930463e-01\n",
      "    1.70243680e-01  9.38565195e-01]\n",
      "  [ 1.46049702e+00  1.49695671e+00  1.29642832e+00 ...  1.66177288e-01\n",
      "    5.67981489e-02  9.86520767e-01]\n",
      "  ...\n",
      "  [ 5.46800375e-01  5.91716826e-01  4.12051201e-01 ...  3.49168211e-01\n",
      "   -2.88644820e-01 -7.01875806e-01]\n",
      "  [-4.03580397e-01 -2.62054086e-01  2.79076070e-01 ...  1.26735447e-02\n",
      "   -5.11806428e-01 -9.19735312e-01]\n",
      "  [-9.39391792e-01 -7.57293642e-01 -4.96022344e-01 ...  5.81896044e-02\n",
      "    3.11543643e-01  3.51130217e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.33044696e+00  6.99502826e-01  1.05002737e+00 ...  1.11429024e+00\n",
      "   -2.52755433e-01 -6.67542696e-01]\n",
      "  [-1.62015166e-02  1.71669777e-02 -7.83676803e-01 ... -3.16517949e-01\n",
      "    2.84114927e-01  5.51062882e-01]\n",
      "  [ 3.03516716e-01 -2.22017597e-02 -4.64844853e-01 ... -1.06617117e+00\n",
      "   -7.73859859e-01 -4.64844853e-01]\n",
      "  ...\n",
      "  [-8.02672803e-02 -1.73019361e+00 -1.48980689e+00 ... -1.29312706e+00\n",
      "   -4.84553874e-01  2.03825980e-01]\n",
      "  [ 7.13597536e-01 -2.04912734e+00 -9.48440135e-01 ...  7.79638767e-01\n",
      "    1.88032591e+00  2.02341533e+00]\n",
      "  [ 3.88826966e-01  1.68247640e+00  1.41296613e+00 ...  1.95198667e+00\n",
      "    2.19454598e+00  2.31582546e+00]]\n",
      "\n",
      " [[ 1.02953398e+00  1.10437047e+00  1.11457551e+00 ...  1.99528903e-01\n",
      "    1.58708990e-01  1.28094047e-01]\n",
      "  [ 1.11880265e-02  7.80909136e-02  1.66121021e-01 ...  6.04848899e-02\n",
      "    1.47092296e-02 -1.08532913e-01]\n",
      "  [ 6.44652247e-02 -4.61820252e-02 -1.01505637e-01 ... -4.72964227e-01\n",
      "   -4.17640597e-01 -4.17640597e-01]\n",
      "  ...\n",
      "  [ 3.17421556e-02  9.13083330e-02  1.83966830e-01 ...  4.02376205e-01\n",
      "    2.10440695e-01  1.11163735e-01]\n",
      "  [-2.54120648e-01  2.40966752e-01  1.61752746e-01 ... -1.31690836e+00\n",
      "   -1.34991419e+00 -1.35651517e+00]\n",
      "  [-4.29602861e-01 -3.76581967e-01 -4.79678184e-01 ... -5.68046331e-01\n",
      "   -5.44481516e-01 -5.12079835e-01]]\n",
      "\n",
      " [[ 1.01915836e+00  6.23192787e-01  4.83440280e-01 ...  1.43841588e+00\n",
      "    1.31419134e+00  1.40735984e+00]\n",
      "  [ 9.04549778e-01  6.98727071e-01  7.23425746e-01 ...  6.49329543e-01\n",
      "    4.51739788e-01  2.37684131e-01]\n",
      "  [ 4.44729887e-02  8.12545270e-02  9.96452868e-02 ...  1.04983485e+00\n",
      "    1.05596519e+00  1.14791906e+00]\n",
      "  ...\n",
      "  [ 9.35055435e-01  1.14792323e+00  1.03764224e+00 ... -1.32698524e+00\n",
      "   -1.22183371e+00 -1.18849301e+00]\n",
      "  [-1.40255833e+00 -1.41759348e+00 -1.41759348e+00 ... -1.71328604e+00\n",
      "   -1.71328604e+00 -1.73834467e+00]\n",
      "  [-1.52807820e+00 -1.54182982e+00 -1.53037012e+00 ... -4.76081580e-01\n",
      "   -4.96708959e-01 -4.64621961e-01]]]\n",
      "[[2 2 2 ... 2 2 2]\n",
      " [2 2 2 ... 2 2 2]\n",
      " [2 2 2 ... 2 2 2]\n",
      " ...\n",
      " [2 2 2 ... 4 4 4]\n",
      " [4 4 4 ... 0 0 0]\n",
      " [2 2 2 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "fold_idx = 0\n",
    "\n",
    "start_time_fold_i = time.time()\n",
    "data_loader = SeqDataLoader(data_dir, num_folds, fold_idx, classes=classes)\n",
    "X_train, y_train, X_test, y_test = data_loader.load_data(seq_len=hparams['max_time_step'])\n",
    "\n",
    "print(start_time_fold_i)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'REM': 4}\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "char2numY = dict(list(zip(classes, list(range(len(classes))))))        \n",
    "pre_f1_macro = 0\n",
    "\n",
    "print(char2numY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'REM', 5: '<SOD>', 6: '<EOD>'}\n"
     ]
    }
   ],
   "source": [
    "# <SOD> is a token to show start of decoding  and <EOD> is a token to indicate end of decoding\n",
    "char2numY['<SOD>'] = len(char2numY)\n",
    "char2numY['<EOD>'] = len(char2numY)\n",
    "num2charY = dict(list(zip(list(char2numY.values()), list(char2numY.keys()))))\n",
    "\n",
    "print(num2charY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # over-sampling: SMOTE:\n",
    "# X_train = np.reshape(X_train,[X_train.shape[0]*X_train.shape[1],-1])\n",
    "# y_train= y_train.flatten()\n",
    "\n",
    "# print('X_train')\n",
    "# print(X_train)\n",
    "\n",
    "# print('y_train')\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63673, 20639, 65555, 12354, 24719]\n"
     ]
    }
   ],
   "source": [
    "nums = []\n",
    "for cl in classes:\n",
    "    nums.append(len(np.where(y_train == char2numY[cl])[0]))\n",
    "\n",
    "print(nums)\n",
    "if (os.path.exists(traindata_dir) == False):\n",
    "    os.mkdir(traindata_dir)\n",
    "fname = os.path.join(traindata_dir,'trainData_'+channel_ename+'_SMOTE_all_10s_f'+str(fold_idx)+'.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (os.path.isfile(fname)):\n",
    "    X_train, y_train,_ = data_loader.load_npz_file(fname)\n",
    "else:\n",
    "    # oversampling\n",
    "    n_osamples = nums[2] - 7000\n",
    "    ratio = {0: n_osamples if nums[0] < n_osamples else nums[0], 1: n_osamples if nums[1] < n_osamples else nums[1],\n",
    "                2: nums[2], 3: n_osamples if nums[3] < n_osamples else nums[3], 4: n_osamples if nums[4] < n_osamples else nums[4]}\n",
    "\n",
    "    sm = SMOTE(random_state=12, sampling_strategy=ratio)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    data_loader.save_to_npz_file(X_train, y_train,data_loader.sampling_rate,fname)\n",
    "\n",
    "    print(n_osamples)\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30191, 10, 3000)\n",
      "(30191, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[:(X_train.shape[0] // hparams['max_time_step']) * hparams['max_time_step'], :]\n",
    "y_train = y_train[:(X_train.shape[0] // hparams['max_time_step']) * hparams['max_time_step']]\n",
    "\n",
    "X_train = np.reshape(X_train,[-1,X_test.shape[1],X_test.shape[2]])\n",
    "y_train = np.reshape(y_train,[-1,y_test.shape[1],])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72612983, 0.7783324 , 0.72612983, ..., 0.6608765 , 0.21715423,\n",
       "       0.47816733], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle training data_2013\n",
    "permute = np.random.permutation(len(y_train))\n",
    "X_train = X_train[permute]\n",
    "y_train = y_train[permute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5032782 , -0.43331504,  0.19317372, ..., -0.08667912,\n",
       "       -0.3410908 ,  0.05324729], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add '<SOD>' to the beginning of each label sequence, and '<EOD>' to the end of each label sequence (both for training and test sets)\n",
    "y_train= [[char2numY['<SOD>']] + [y_ for y_ in date] + [char2numY['<EOD>']] for date in y_train]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "y_test= [[char2numY['<SOD>']] + [y_ for y_ in date] + [char2numY['<EOD>']] for date in y_test]\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30191, 10, 3000, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# NumPy  PyTorch  \n",
    "input_tensor = torch.from_numpy(X_train)\n",
    "\n",
    "#   (30191, 10, 3000) -> (30191, 10, 3000, 1)\n",
    "input_tensor = input_tensor.unsqueeze(-1)\n",
    "\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7547, 21, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:294: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\\aten\\src\\ATen\\native\\Convolution.cpp:660.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# m = nn.Conv1d(10, 64, 400, stride=50)\n",
    "input_ = torch.randn(7547, 10, 3000).to('cuda')\n",
    "cnn1 = nn.Sequential(\n",
    "    nn.Conv1d(10, 64, 50, stride=6),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(8, stride=8),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Conv1d(64, 128, 8, stride=1, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(128, 128, 8, stride=1, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(128, 128, 8, stride=1, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(4, stride=4),\n",
    ").to('cuda')\n",
    "\n",
    "cnn2 = nn.Sequential(\n",
    "    nn.Conv1d(10, 64, 400, stride=50),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(4, stride=4),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Conv1d(64, 128, 6, stride=1, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(128, 128, 6, stride=1, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(128, 128, 6, stride=1, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2, stride=2),\n",
    ").to('cuda')\n",
    "output1 = cnn1(input_)\n",
    "output2 = cnn2(input_)\n",
    "out = torch.cat((output1, output2), dim = -1)\n",
    "cnnout = out.transpose(1, 2)\n",
    "print(cnnout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7547, 21, 256])\n",
      "torch.Size([4, 7547, 128])\n",
      "torch.Size([4, 7547, 128])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(128, 128, num_layers = 2, bidirectional = True, batch_first = True).to('cuda')\n",
    "encoder_outputs, encoder_state = lstm(cnnout)\n",
    "print(encoder_outputs.shape)\n",
    "print(encoder_state[0].shape)\n",
    "print(encoder_state[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 3, ..., 3, 3, 6],\n",
       "       [5, 3, 3, ..., 3, 3, 6],\n",
       "       [5, 0, 0, ..., 0, 0, 6],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 6],\n",
       "       [5, 2, 2, ..., 2, 2, 6],\n",
       "       [5, 0, 0, ..., 0, 0, 6]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30191, 12)\n",
      "torch.Size([30191, 7])\n",
      "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "decoder_input = torch.zeros(y_train.shape[0], 7)  # Assuming <SOD> token representation\n",
    "decoder_input[:, char2numY['<SOD>']] = 1\n",
    "\n",
    "print(y_train.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(encoder, decoder, inputs, target, optimizer, loss_object):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    encoder_output, hidden_state = encoder(inputs)\n",
    "    decoder_input = torch.zeros(target.shape[0], NUM_CLASSES+2)  # Assuming <SOD> token representation\n",
    "    decoder_input[:, char2numY['<SOD>']] = 1\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(SEQUENCE_LENGTH):\n",
    "        pred, hidden_state = decoder(decoder_input, hidden_state, encoder_output)\n",
    "        loss += loss_object(pred, target[:, t])\n",
    "        decoder_input = F.one_hot(target[:, t], num_classes=NUM_CLASSES+2).float()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Attention, self).__init__()\n",
    "        self.We = nn.Linear(2 * kargs['num_units'], 2 * kargs['num_units'],)\n",
    "        self.Wh = nn.Linear(2 * kargs['num_units'], 2 * kargs['num_units'],)\n",
    "        \n",
    "    def forward(self, encoder_hidden, decoder_hidden):\n",
    "        WE = self.We(encoder_hidden)\n",
    "        decoder_hidden = torch.unsqueeze(decoder_hidden, 1)\n",
    "        WH = self.Wh(decoder_hidden)\n",
    "        x = torch.cat((WE, WH), dim = - 1)\n",
    "        f = torch.tanh(x)\n",
    "        alpha = torch.nn.functional.softmax(f, dim=-1)\n",
    "        c = alpha * encoder_hidden\n",
    "        c = torch.sum(c, axis=1)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS= 7\n",
    "kargs = {\n",
    "    'epochs': 120,\n",
    "    'batch_size': 20,\n",
    "    'num_units': 128,\n",
    "    'embed_size': 10,\n",
    "    'input_depth': 3000,\n",
    "    'n_channels': 100,\n",
    "    'bidirectional': False,\n",
    "    'use_attention': True,\n",
    "    'lstm_layers': 2,\n",
    "    'attention_size': 64,\n",
    "    'beam_width': 4,\n",
    "    'use_beamsearch_decode': False,\n",
    "    'max_time_step': 10,\n",
    "    'output_max_length': 10 + 2,\n",
    "    'akara2017': True,\n",
    "    'test_step': 5\n",
    "}\n",
    "We = nn.Linear(2 * kargs['num_units'], 2 * kargs['num_units']).to('cuda')\n",
    "Wh = nn.Linear(2 * kargs['num_units'], 2 * kargs['num_units']).to('cuda')\n",
    "lstm = nn.LSTM(2 * kargs['num_units'], 2 * kargs['num_units'], num_layers = kargs['lstm_layers'], bidirectional = True, batch_first = True).to('cuda')\n",
    "classes = nn.Linear(2 * kargs['num_units'], NUM_CLASS).to('cuda')\n",
    "softmax = nn.Softmax(dim=-1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7547, 7])\n"
     ]
    }
   ],
   "source": [
    "decoder_input = F.one_hot(torch.tensor(char2numY['<SOD>']), num_classes=7).float()\n",
    "decoder_input = decoder_input.expand(input_.shape[0], -1)  # <SOD> \n",
    "print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.cat((encoder_state[0], encoder_state[1]), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7547, 21, 256])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7547, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7547, 21, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7547, 256])\n",
      "torch.Size([7547, 1, 21, 256])\n"
     ]
    }
   ],
   "source": [
    "print(WE.shape)\n",
    "print(WH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7547, 21, 256])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 7547 and 4 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\sejin\\GoodSleep\\test.ipynb Cell 38\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y124sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m decoder_hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(encoder_outputs, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y124sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m WH \u001b[39m=\u001b[39m Wh(encoder_outputs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y124sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((WE, WH), dim \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y124sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y124sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m alpha \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(f, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 7547 and 4 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "WE = We(h)\n",
    "decoder_hidden = torch.unsqueeze(encoder_outputs, 1)\n",
    "WH = Wh(encoder_outputs)\n",
    "x = torch.cat((WE, WH), dim = -1)\n",
    "f = torch.tanh(x)\n",
    "alpha = torch.nn.functional.softmax(f, dim=-1)\n",
    "c = alpha * encoder_outputs\n",
    "c = torch.sum(c, axis=1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (158487x512 and 256x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\sejin\\GoodSleep\\test.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m c \u001b[39m=\u001b[39m attention(encoder_outputs, h)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(c\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([c, decoder_input], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\sejin\\GoodSleep\\test.ipynb Cell 35\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, encoder_hidden, decoder_hidden):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     WE \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mWe(encoder_hidden)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     decoder_hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(decoder_hidden, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sejin/GoodSleep/test.ipynb#Y115sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     WH \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWh(decoder_hidden)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[0;32m   1846\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[1;32m-> 1847\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (158487x512 and 256x256)"
     ]
    }
   ],
   "source": [
    "c = attention(encoder_outputs, h)\n",
    "print(c.shape)\n",
    "x = torch.cat([c, decoder_input], dim=-1).unsqueeze(1)\n",
    "print(x.shape)\n",
    "x, h = lstm(x) # .squeeze(1)\n",
    "print(h.shape)\n",
    "prediction = softmax(classes(x))\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30191, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The training set after oversampling: ', ['W', 'N1', 'N2', 'N3', 'REM'])\n",
      "('W', 61734)\n",
      "('N1', 58294)\n",
      "('N2', 65294)\n",
      "('N3', 58294)\n",
      "('REM', 58294)\n"
     ]
    }
   ],
   "source": [
    "print(('The training set after oversampling: ', classes))\n",
    "\n",
    "for cl in classes:\n",
    "    print((cl, len(np.where(y_train==char2numY[cl])[0])))\n",
    "\n",
    "# training and testing the model\n",
    "if (os.path.exists(checkpoint_dir) == False):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "if (os.path.exists(output_dir) == False):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x, y, batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "#     from IPython.core.debugger import Tracer; Tracer()()\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    while start + batch_size <= len(x):\n",
    "        yield x[start:start+batch_size], y[start:start+batch_size]\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "lstm_layers = 2\n",
    "lstm_units = 128\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=lstm_units, hidden_size=lstm_units, num_layers=lstm_layers, bidirectional=True, batch_first=True)\n",
    "    \n",
    "    def forward(self, data_input_embed):\n",
    "        encoder_outputs, encoder_state = self.lstm(data_input_embed)\n",
    "        return encoder_outputs, encoder_state\n",
    "\n",
    "encoder = Encoder()\n",
    "encoder_outputs, encoder_state = encoder(data_input_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Decoder, self).__init__()\n",
    "        if not hparams['bidirectional']:\n",
    "            self.lstm = nn.LSTM(input_size=hparams['num_units'], hidden_size=hparams['num_units'], num_layers=hparams['lstm_layers'], batch_first=True)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_size=2*hparams['num_units'], hidden_size=2*hparams['num_units'], num_layers=hparams['lstm_layers'], batch_first=True)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        decoder_outputs, decoder_state = self.lstm(x)\n",
    "        return decoder_outputs, decoder_state\n",
    "\n",
    "decoder = Decoder(hparams)\n",
    "decoder_outputs, decoder_state = decoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq-to-seq\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim          \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self, inp):\n",
    "        return tf.zeros((tf.shape(inp)[0], self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq-to-seq\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim  \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "            \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "decoder_input = torch.zeros(y_train.shape[0], 7)  # Assuming <SOD> token representation\n",
    "decoder_input[:, char2numY['<SOD>']] = 1\n",
    "\n",
    "print(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, cnn):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lstm_f = nn.LSTM(128, 128, batch_first=True)\n",
    "        self.lstm_b = nn.LSTM(128, 128, batch_first=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = [self.cnn(inputs[:, i]) for i in range(inputs.shape[1])]\n",
    "        x = torch.stack(x, dim=1)\n",
    "        f, (fh, _) = self.lstm_f(x)\n",
    "        b, (bh, _) = self.lstm_b(x)\n",
    "        x = torch.cat([f, b], dim=-1)\n",
    "        h = torch.cat([fh, bh], dim=-1)\n",
    "        return x, h\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, latent):\n",
    "        super(Attention, self).__init__()\n",
    "        self.We = nn.Linear(latent, latent)\n",
    "        self.Wh = nn.Linear(latent, latent)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, encoder_hidden, decoder_hidden):\n",
    "        WE = self.We(encoder_hidden)\n",
    "        WH = self.Wh(decoder_hidden.unsqueeze(1))\n",
    "        x = WE + WH\n",
    "        f = self.tanh(x)\n",
    "        alpha = self.softmax(f)\n",
    "        c = alpha * encoder_hidden\n",
    "        c = torch.sum(c, dim=1)\n",
    "        return c\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm_f = nn.LSTM(128 + 256, 128, batch_first=True)\n",
    "        self.lstm_b = nn.LSTM(128 + 256, 128, batch_first=True)\n",
    "        self.attention = Attention(256)\n",
    "        self.classes = nn.Linear(256, 7)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, decoder_input, prev_decoder_hidden, encoder_hidden):\n",
    "        c = self.attention(encoder_hidden, prev_decoder_hidden)\n",
    "        x = torch.cat([c, decoder_input], dim=-1).unsqueeze(1)\n",
    "        f, (fh, _) = self.lstm_f(x)\n",
    "        b, (bh, _) = self.lstm_b(x)\n",
    "        h = torch.cat([fh, bh], dim=-1)\n",
    "        x = torch.cat([f, b], dim=-1).squeeze(1)\n",
    "        prediction = self.softmax(self.classes(x))\n",
    "        return prediction, h\n",
    "\n",
    "\n",
    "loss_object = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=ETA)\n",
    "\n",
    "\n",
    "\n",
    "def train_step(encoder, decoder, inputs, target, optimizer, loss_object):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    encoder_output, hidden_state = encoder(inputs)\n",
    "    decoder_input = torch.zeros(target.shape[0], NUM_CLASSES+2)  # Assuming <SOD> token representation\n",
    "    decoder_input[:, char2numY['<SOD>']] = 1\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(SEQUENCE_LENGTH):\n",
    "        pred, hidden_state = decoder(decoder_input, hidden_state, encoder_output)\n",
    "        loss += loss_object(pred, target[:, t])\n",
    "        decoder_input = F.one_hot(target[:, t], num_classes=NUM_CLASSES+2).float()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "def train_step(inputs):\n",
    "    _X, _y = inputs\n",
    "    _y = F.one_hot(torch.tensor(_y), num_classes=NUM_CLASSES+2).float()\n",
    "\n",
    "    _loss = 0.\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    encoder_output, hidden_state = encoder(_X)\n",
    "\n",
    "    decoder_input = F.one_hot(torch.tensor(char2numY['<SOD>']), num_classes=NUM_CLASSES+2).float()\n",
    "    decoder_input = decoder_input.expand(_X.shape[0], -1)  # <SOD> \n",
    "\n",
    "    for t in range(SEQUENCE_LENGTH):\n",
    "        pred, hidden_state = decoder(decoder_input, hidden_state, encoder_output)\n",
    "        _loss += loss_object(_y[:, t, :], pred)\n",
    "        acc.update_state(acc_object(_y[:, t, :], pred))\n",
    "        loss.update_state(_loss.item())\n",
    "        decoder_input = _y[:, t, :].argmax(dim=1)\n",
    "\n",
    "    _loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = F.one_hot(torch.tensor(char2numY['<SOD>']), num_classes=7).float()\n",
    "decoder_input = decoder_input.expand(X_train.shape[0], -1)  # <SOD> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30191, 12, 7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.one_hot(torch.tensor(y_train, dtype=torch.long), num_classes=7).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 4, ..., 2, 1, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "decoder_input = F.one_hot(torch.tensor(char2numY['<SOD>']), num_classes=NUM_CLASSES+2).float()\n",
    "decoder_input = decoder_input.expand(_X.shape[0], -1)  # <SOD> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = torch.zeros(target.shape[0], NUM_CLASSES+2)  # Assuming <SOD> token representation\n",
    "decoder_input[:, char2numY['<SOD>']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MFE: 0.008935185185185187\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean Squared Error \n",
    "    \"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def classwise_mfe(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "     MFE \n",
    "    \"\"\"\n",
    "    mfe_dict = {}\n",
    "    \n",
    "    for c in classes:\n",
    "        #  c    \n",
    "        indices = np.where(y_true == c)[0]\n",
    "        \n",
    "        #  c     \n",
    "        y_true_c = y_true[indices]\n",
    "        y_pred_c = y_pred[indices]\n",
    "        \n",
    "        #  c   \n",
    "        C_i = len(indices)\n",
    "        \n",
    "        # MFE   \n",
    "        mfe_dict[c] = mean_squared_error(y_true_c, y_pred_c) / C_i\n",
    "    \n",
    "    return mfe_dict\n",
    "\n",
    "def overall_mfe(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "     MFE \n",
    "    \"\"\"\n",
    "    #  MFE \n",
    "    class_mfe = classwise_mfe(y_true, y_pred, classes)\n",
    "    \n",
    "    #  MFE \n",
    "    overall_mfe = np.mean(list(class_mfe.values()))\n",
    "    \n",
    "    return overall_mfe\n",
    "\n",
    "#  \n",
    "y_true = np.array([1, 1, 2, 2, 2, 3, 3, 3, 3])\n",
    "y_pred = np.array([1.1, 1.2, 2.1, 2.0, 2.2, 3.2, 3.0, 3.1, 3.3])\n",
    "classes = np.unique(y_true)\n",
    "\n",
    "#  MFE \n",
    "mfe_result = overall_mfe(y_true, y_pred, classes)\n",
    "\n",
    "#  \n",
    "print(f\"Overall MFE: {mfe_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2, 2, ..., 3, 2, 6],\n",
       "       [5, 4, 4, ..., 4, 4, 6],\n",
       "       [5, 4, 4, ..., 4, 4, 6],\n",
       "       ...,\n",
       "       [5, 2, 2, ..., 4, 4, 6],\n",
       "       [5, 1, 1, ..., 1, 1, 6],\n",
       "       [5, 4, 4, ..., 4, 4, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from preprocess import *\n",
    "def dataload(index_inputs, index_outputs, index_targets):\n",
    "    #  a \n",
    "    length = len(index_inputs)\n",
    "\n",
    "    #    \n",
    "    num_samples = length // 10\n",
    "\n",
    "    #    \n",
    "    val_index = random.sample(range(length), num_samples)\n",
    "    train_index = [i for i in range(length) if i not in val_index]\n",
    "\n",
    "    train_inputs=[index_inputs[i] for i in train_index]\n",
    "    train_outputs=[index_outputs[i] for i in train_index]\n",
    "    train_targets=[index_targets[i] for i in train_index]\n",
    "\n",
    "    val_inputs=[index_inputs[i] for i in val_index]\n",
    "    val_outputs=[index_outputs[i] for i in val_index]\n",
    "    val_targets=[index_targets[i] for i in val_index]\n",
    "\n",
    "    return train_inputs, train_outputs, train_targets, val_inputs, val_outputs, val_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))\n",
    "\n",
    "train_inputs, train_outputs, train_targets, val_inputs, val_outputs, val_targets = dataload(index_inputs, index_outputs, index_targets)\n",
    "\n",
    "\n",
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "model_name = 'transformer'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 30\n",
    "learning_rate = 1e-4\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "        'num_layers': 2,\n",
    "        'd_model': 512,\n",
    "        'num_heads': 8,\n",
    "        'dff': 2048,\n",
    "        'input_vocab_size': vocab_size,\n",
    "        'target_vocab_size': vocab_size,\n",
    "        'maximum_position_encoding': MAX_SEQUENCE,\n",
    "        'end_token_idx': char2idx[end_index],\n",
    "        'rate': 0.1,\n",
    "        'epochs':EPOCHS,\n",
    "        'batch_size':BATCH_SIZE,\n",
    "        'train_index_inputs':train_inputs,\n",
    "        'train_index_outputs':train_outputs,\n",
    "        'train_index_targets':train_targets,\n",
    "        'val_index_inputs':val_inputs,\n",
    "        'val_index_outputs':val_outputs,\n",
    "        'val_index_targets':val_targets,\n",
    "        'learning_rate': learning_rate\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 25)\n",
      "(18, 25)\n",
      "(18, 25)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_inputs).shape)\n",
    "print(np.array(train_outputs).shape)\n",
    "print(np.array(train_targets).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([450])\n",
      "torch.Size([50])\n",
      "torch.Size([450])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "train_real = torch.tensor(kargs['train_index_targets'], dtype=torch.long).view(-1)\n",
    "val_real = torch.tensor(kargs['val_index_targets'], dtype=torch.long).view(-1)\n",
    "train_mask = ~torch.eq(train_real, 0)\n",
    "val_mask = ~torch.eq(val_real, 0)\n",
    "train_cost = []\n",
    "val_cost = []\n",
    "\n",
    "print(train_real.shape)\n",
    "print(val_real.shape)\n",
    "print(train_mask.shape)\n",
    "print(val_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor(kargs['train_index_inputs'])\n",
    "tar = torch.tensor(kargs['train_index_outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kargs['input_vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = F.one_hot(torch.tensor(y_train, dtype=torch.long), num_classes=7).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30191, 12, 7])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 25, 512])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=kargs['input_vocab_size'], \n",
    "                               embedding_dim=512)\n",
    "\n",
    "x = embedding(inp)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
